
@article{perfors_why_nodate,
	title = {Why do echo chambers form? {The} role of trust, population heterogeneity, and objective truth},
	abstract = {Many real-world situations involve learning entirely or mostly based on the information provided by other people, which creates a thorny epistemological problem: how does one determine which of those people to trust? Previous work has shown that even populations of rational Bayesian agents, faced with this problem, polarise into “echo chambers” characterised by different beliefs and low levels of between-group trust. In this study we show that this general result holds even when the reasoners have a more complex meaning space and can communicate about their beliefs in a more nuanced way. However, even a tiny amount of exposure to a mutually trusted “ground truth” is sufﬁcient to eliminate polarisation. Societal and psychological implications are discussed.},
	language = {en},
	author = {Perfors, Amy and Navarro, Danielle J.},
	pages = {6}
}

@inproceedings{perfors_why_2019,
	title = {Why do echo chambers form? {The} role of trust, population heterogeneity, and objective truth},
	abstract = {Many real-world situations involve learning entirely or mostly based on the information provided by other people, which creates a thorny epistemological problem: how does one determine which of those people to trust? Previous work has shown that even populations of rational Bayesian agents, faced with this problem, polarise into “echo chambers” characterised by different beliefs and low levels of between-group trust. In this study we show that this general result holds even when the reasoners have a more complex meaning space and can communicate about their beliefs in a more nuanced way. However, even a tiny amount of exposure to a mutually trusted “ground truth” is sufﬁcient to eliminate polarisation. Societal and psychological implications are discussed.},
	language = {en},
	booktitle = {Proceedings of the 41st {Annual} {Conference} of the {Cognitive} {Science} {Society}},
	author = {Perfors, Amy and Navarro, Danielle J.},
	year = {2019},
	pages = {918--923}
}

@article{navarro_between_2019,
	title = {Between the devil and the deep blue sea: {Tensions} between scientific judgement and statistical model selection},
	volume = {2},
	issn = {2522-087X},
	shorttitle = {Between the {Devil} and the {Deep} {Blue} {Sea}},
	url = {https://doi.org/10.1007/s42113-018-0019-z},
	doi = {10.1007/s42113-018-0019-z},
	abstract = {Discussions of model selection in the psychological literature typically frame the issues as a question of statistical inference, with the goal being to determine which model makes the best predictions about data. Within this setting, advocates of leave-one-out cross-validation and Bayes factors disagree on precisely which prediction problem model selection questions should aim to answer. In this comment, I discuss some of these issues from a scientific perspective. What goal does model selection serve when all models are known to be systematically wrong? How might “toy problems” tell a misleading story? How does the scientific goal of explanation align with (or differ from) traditional statistical concerns? I do not offer answers to these questions, but hope to highlight the reasons why psychological researchers cannot avoid asking them.},
	language = {en},
	number = {1},
	urldate = {2020-07-03},
	journal = {Computational Brain \& Behavior},
	author = {Navarro, Danielle J.},
	month = mar,
	year = {2019},
	pages = {28--34}
}

@article{woensdregt_computational_2019,
	title = {A computational model of the cultural co-evolution of language and mindreading},
	doi = {10.31234/osf.io/3bmsx},
	abstract = {Several evolutionary accounts of human social cognition posit that language has co-evolved with the sophisticated mindreading abilities of modern humans. It has also been argued that these mindreading abilities are the product of cultural, rather than biological, evolution. Taken together, these claims suggest that the evolution of language has played an important role in the cultural evolution of human social cognition. Here we present a new computational model which formalises the assumptions that underlie this hypothesis, in order to explore how language and mindreading interact through cultural evolution. This model treats communicative behaviour as an interplay between the context in which communication occurs, an agent’s individual perspective on the world, and the agent’s lexicon. However, each agent’s perspective and lexicon are private mental representations, not directly observable to other agents. Learners are therefore confronted with the task of jointly inferring the lexicon and perspective of their cultural parent, based on their utterances in context. Simulation results show that given these assumptions, an informative lexicon evolves not just under a pressure to be successful at communicating, but also under a pressure for accurate perspective inference. When such a lexicon evolves, agents become better at inferring others’ perspectives; not because their innate ability to learn about perspectives changes, but because sharing a language (of the right type) with others helps them to do so.},
	author = {Woensdregt, Marieke and Cummins, Chris and Smith, Kenny},
	year = {2019},
	note = {To appear in Synthese.}
}

@book{thagard_hot_2006,
	title = {Hot {Thought}},
	abstract = {Contrary to standard assumptions, reasoning is often an emotional process. Emotions can have good effects, as when a scientist gets excited about a line of research and pursues it successfully despite criticism. But emotions can also distort reasoning, as when a juror ignores evidence of guilt just because the accused seems like a nice guy. In Hot Thought, Paul Thagard describes the mental mechanisms—cognitive, neural, molecular, and social—that interact to produce different kinds of human thinking, from everyday decision making to legal reasoning, scientific discovery, and religious belief, and he discusses when and how thinking and reasoning should be emotional.Thagard argues that an understanding of emotional thinking needs to integrate the cognitive, neural, molecular, and social levels. Many of the chapters employ computational models of various levels of thinking, including HOTCO (hot cognition) models and the more neurologically realistic GAGE model. Thagard uses these models to illuminate thinking in the domains of law, science, and religion, discussing such topics as the role of doubt and reasonable doubt in legal and other contexts, valuable emotional habits for successful scientists, and the emotional content of religious beliefs. Identifying and assessing the impact of emotion, Thagard argues, can suggest ways to improve the process of reasoning.},
	language = {en},
	author = {Thagard, Paul},
	year = {2006},
	note = {The MIT Press}
}

@book{thagard_coherence_2000,
	title = {Coherence in {Thought} and {Action}},
	abstract = {This book is an essay on how people make sense of each other and the world they live in. Making sense is the activity of fitting something puzzling into a coherent pattern of mental representations that include concepts, beliefs, goals, and actions. Paul Thagard proposes a general theory of coherence as the satisfaction of multiple interacting constraints, and discusses the theory's numerous psychological and philosophical applications. Much of human cognition can be understood in terms of coherence as constraint satisfaction, and many of the central problems of philosophy can be given coherence-based solutions. Thagard shows how coherence can help to unify psychology and philosophy, particularly when addressing questions of epistemology, metaphysics, ethics, politics, and aesthetics. He also shows how coherence can integrate cognition and emotion.},
	language = {en},
	author = {Thagard, Paul},
	year = {2000},
	note = {The MIT Press}
}

@article{van_rooij_theory_2020,
	title = {Theory before the test: {How} to build high-verisimilitude explanatory theories in psychological science},
	shorttitle = {Theory before the test},
	doi = {10.31234/osf.io/7qbpr},
	abstract = {Drawing on the philosophy of psychological explanation (Cummins, 1983; 2000), we suggest that psychological science, by focusing on effects, may lose sight of its primary explananda: psychological capacities. We revisit Marr’s (1982) levels-of-analysis framework, which has been remarkably productive and useful for cognitive psychological explanation. We discuss ways in which Marr’s framework may be extended to other areas of psychology, such as social, developmental, and evolutionary psychology, bringing new benefits to these fields. Next, we show how theoretical analyses can endow a theory with minimal plausibility even prior to contact with empirical data: we call this the theoretical cycle. Finally, we explain how our proposal may contribute to addressing critical issues in psychological science, including how to leverage effects to understand capacities better.},
	author = {van Rooij, Iris and Baggio, Giosuè},
	month = feb,
	year = {2020}
}

@article{szollosi_is_2020,
	title = {Is peregistration worthwhile?},
	volume = {24},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(19)30285-2},
	doi = {10.1016/j.tics.2019.11.009},
	language = {English},
	number = {2},
	urldate = {2020-07-03},
	journal = {Trends in Cognitive Sciences},
	author = {Szollosi, Aba and Kellen, David and Navarro, Danielle J. and Shiffrin, Richard and van Rooij, Iris and Van Zandt, Trisha and Donkin, Chris},
	month = feb,
	year = {2020},
	keywords = {inference, preregistration, theory development},
	pages = {94--95}
}

@article{rich_how_2020,
	title = {How intractability spans the cognitive and evolutionary levels of explanation},
	copyright = {© 2020 The Authors. Topics in Cognitive Science  published by Wiley Periodicals LLC on behalf of Cognitive Science Society},
	issn = {1756-8765},
	doi = {10.1111/tops.12506},
	abstract = {The challenge of explaining how cognition can be tractably realized is widely recognized. Classical rationality is thought to be intractable due to its assumptions of optimization and/or domain generality, and proposed solutions therefore drop one or both of these assumptions. We consider three such proposals: Resource-Rationality, the Adaptive Toolbox theory, and Massive Modularity. All three seek to ensure the tractability of cognition by shifting part of the explanation from the cognitive to the evolutionary level: Evolution is responsible for producing the tractable architecture. We consider the three proposals and show that, in each case, the intractability challenge is not thereby resolved, but only relocated from the cognitive level to the evolutionary level. We explain how non-classical accounts do not currently have the upper hand on the new playing field.},
	language = {en},
	urldate = {2020-07-04},
	journal = {Topics in Cognitive Science},
	author = {Rich, Patricia and Blokpoel, Mark and de Haan, Ronald and van Rooij, Iris},
	year = {2020},
	keywords = {Evolution, Heuristics, Intractability, Levels of explanation, Modularity, Rationality}
}

@techreport{blokpoel_pragmatic_2019,
	type = {preprint},
	title = {Pragmatic communicators can overcome asymmetry by exploiting ambiguity},
	url = {https://osf.io/q56xs},
	abstract = {How can people communicate successfully when they perceive the world differently (asymmetry) and when words can mean different things (ambiguity)? Prior work has appealed to contextual information to blunt the impact of ambiguity, and explicit feedback to resolve misunderstandings caused by asymmetry. We demonstrate that even without contextual scaffolding and before resorting to interactive feedback, communicators using pragmatic inference can actually exploit ambiguity to overcome asymmetry. While intuition suggests that ambiguity only aggravates asymmetry, agent-based simulations show that to pragmatic communicators it is a ‘helping hand’: They can use ambiguity to trade computationally leaner pragmatic inference for costly interactional turbulence. This computational approach to a longstanding linguistic problem establishes a novel theoretical baseline for explaining natural language use.},
	institution = {Open Science Framework},
	author = {Blokpoel, Mark and Dingemanse, Mark and Woensdregt, Marieke and Kachergis, George and Bögels, Sara and Toni, Ivan and van Rooij, Iris},
	month = nov,
	year = {2019},
	doi = {10.31219/osf.io/q56xs}
}

@article{baker_goal_2007,
	title = {Goal inference as inverse planning},
	volume = {29},
	issn = {1069-7977},
	abstract = {Author(s): Baker, Chris L.; Tenenbaum, J.B.; Saxe, Rebecca R.},
	language = {en},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Baker, Chris L. and Tenenbaum, J. B. and Saxe, Rebecca R.},
	year = {2007}
}

@inproceedings{krafft_levels_2018,
	title = {Levels of {Analysis} in {Computational} {Social} {Science}},
	abstract = {Marr’s levels of analysis constitute one inﬂuential approach to the central program of cognitive science—the multilevel analysis of cognition as information processing. The distinctive aspects of Marr’s framework are an emphasis on identifying the computational problems and constraints faced in cognition, and conceptual machinery to relate cognitive mechanisms to that computational level of analysis. Although related ideas have been explored in a range of social science disciplines, Marr’s framework, and particularly its notion of the precise formulation of computational problems and solutions, has yet to be applied widely in social analysis. In the present work we develop a formulation of Marr’s levels for social systems, provide examples of this approach, and address potential criticisms. The consequence is a computational perspective on the sociological school of structural functionalism, and an apparatus for conducting multiscale analysis of social systems.},
	language = {en},
	author = {Krafft, Peter M and Grifﬁths, Thomas L},
	year = {2018},
	pages = {6}
}

@misc{noauthor_notitle_nodate,
	url = {https://cogsci.mindmodeling.org/2019/papers/0172/index.html},
	urldate = {2020-07-04}
}

@article{navarro_when_2018,
	title = {When {Extremists} {Win}: {Cultural} {Transmission} {Via} {Iterated} {Learning} {When} {Populations} {Are} {Heterogeneous}},
	volume = {42},
	copyright = {© 2018 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	shorttitle = {When {Extremists} {Win}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12667},
	doi = {10.1111/cogs.12667},
	abstract = {How does the process of information transmission affect the cultural or linguistic products that emerge? This question is often studied experimentally and computationally via iterated learning, a procedure in which participants learn from previous participants in a chain. Iterated learning is a powerful tool because, when all participants share the same priors, the stationary distributions of the iterated learning chains reveal those priors. In many situations, however, it is unreasonable to assume that all participants share the same prior beliefs. We present four simulation studies and one experiment demonstrating that when the population of learners is heterogeneous, the behavior of an iterated learning chain can be unpredictable and is often systematically distorted by the learners with the most extreme biases. This results in group-level outcomes that reflect neither the behavior of any individuals within the population nor the overall population average. We discuss implications for the use of iterated learning as a methodological tool as well as for the processes that might have shaped cultural and linguistic evolution in the real world.},
	language = {en},
	number = {7},
	urldate = {2020-07-04},
	journal = {Cognitive Science},
	author = {Navarro, Danielle J. and Perfors, Amy and Kary, Arthur and Brown, Scott D. and Donkin, Chris},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12667},
	keywords = {Bayesian cognition, Cultural evolution, Inductive biases, Iterated learning, Language evolution},
	pages = {2108--2149}
}

@article{smith_agent-based_2007,
	title = {Agent-based modeling: {A} new approach for theory-building in social psychology},
	volume = {11},
	shorttitle = {Agent-based modeling},
	journal = {Personality and Social Psychology Review},
	author = {Smith, Eliot R. and Conrey, Frederica R.},
	year = {2007},
	pages = {87--104}
}

@article{krafft_levels_2018-1,
	title = {Levels of {Analysis} in {Computational} {Social} {Science}},
	abstract = {Marr’s levels of analysis constitute one influential approach to the central program of cognitive science—the multilevel analysis of cognition as information processing. The distinctive aspects of Marr’s framework are an emphasis on identifying the computational problems and constraints faced in cognition, and conceptual machinery to relate cognitive mechanisms to that computational level of analysis. Although related ideas have been explored in a range of social science disciplines, Marr’s framework, and particularly its notion of the precise formulation of computational problems and solutions, has yet to be applied widely in social analysis. In the present work we develop a formulation of Marr’s levels for social systems, provide examples of this approach, and address potential criticisms. The consequence is a computational perspective on the sociological school of structural functionalism, and an apparatus for conducting multiscale analysis of social systems.},
	journal = {CogSci},
	author = {Krafft, Peter and Griffiths, Tom},
	year = {2018}
}

@article{krafft_levels_nodate,
	title = {Levels of {Analysis} in {Computational} {Social} {Science}},
	abstract = {Marr’s levels of analysis constitute one inﬂuential approach to the central program of cognitive science—the multilevel analysis of cognition as information processing. The distinctive aspects of Marr’s framework are an emphasis on identifying the computational problems and constraints faced in cognition, and conceptual machinery to relate cognitive mechanisms to that computational level of analysis. Although related ideas have been explored in a range of social science disciplines, Marr’s framework, and particularly its notion of the precise formulation of computational problems and solutions, has yet to be applied widely in social analysis. In the present work we develop a formulation of Marr’s levels for social systems, provide examples of this approach, and address potential criticisms. The consequence is a computational perspective on the sociological school of structural functionalism, and an apparatus for conducting multiscale analysis of social systems.},
	language = {en},
	author = {Krafft, Peter M and Grifﬁths, Thomas L},
	pages = {6}
}

@misc{noauthor_coherence_nodate,
	title = {Coherence in {Thought} and {Action} : {Paul} {Thagard} : 9780262700924},
	url = {https://www.bookdepository.com/Coherence-Thought-Action-Paul-Thagard/9780262700924},
	urldate = {2020-07-04}
}

@misc{noauthor_coherence_nodate-1,
	title = {Coherence in {Thought} and {Action} {\textbar} {MIT} {CogNet}},
	url = {http://cognet.mit.edu/book/coherence-thought-and-action},
	urldate = {2020-07-04}
}

@misc{press_coherence_nodate,
	title = {Coherence in {Thought} and {Action} {\textbar} {The} {MIT} {Press}},
	url = {https://mitpress.mit.edu/books/coherence-thought-and-action},
	abstract = {This book is an essay on how people make sense of each other and the world they live in. Making sense is the activity of fitting something puzzling into a coherent pattern of mental representations that include concepts, beliefs, goals, and actions. Paul Thagard proposes a general theory of coherence as the satisfaction of multiple interacting constraints, and discusses the theory's numerous psychological and philosophical applications. Much of human cognition can be understood in terms of coherence as constraint satisfaction, and many of the central problems of philosophy can be given coherence-based solutions. Thagard shows how coherence can help to unify psychology and philosophy, particularly when addressing questions of epistemology, metaphysics, ethics, politics, and aesthetics. He also shows how coherence can integrate cognition and emotion.},
	language = {en},
	urldate = {2020-07-04},
	author = {Press, The MIT},
	note = {Library Catalog: mitpress.mit.edu
Publisher: The MIT Press}
}

@misc{press_coherence_nodate-1,
	title = {Coherence in {Thought} and {Action} {\textbar} {The} {MIT} {Press}},
	url = {https://mitpress.mit.edu/books/coherence-thought-and-action},
	abstract = {This book is an essay on how people make sense of each other and the world they live in. Making sense is the activity of fitting something puzzling into a coherent pattern of mental representations that include concepts, beliefs, goals, and actions. Paul Thagard proposes a general theory of coherence as the satisfaction of multiple interacting constraints, and discusses the theory's numerous psychological and philosophical applications. Much of human cognition can be understood in terms of coherence as constraint satisfaction, and many of the central problems of philosophy can be given coherence-based solutions. Thagard shows how coherence can help to unify psychology and philosophy, particularly when addressing questions of epistemology, metaphysics, ethics, politics, and aesthetics. He also shows how coherence can integrate cognition and emotion.},
	language = {en},
	urldate = {2020-07-04},
	author = {Press, The MIT},
	note = {Library Catalog: mitpress.mit.edu
Publisher: The MIT Press}
}

@article{klapper_social_2018,
	title = {Social categorization in connectionist models: {A} conceptual integration},
	volume = {36},
	issn = {0278-016X},
	shorttitle = {Social {Categorization} in {Connectionist} {Models}},
	url = {https://guilfordjournals.com/doi/10.1521/soco.2018.36.2.221},
	doi = {10.1521/soco.2018.36.2.221},
	abstract = {We present a conceptual integration of two major types of social perception models. First, according to social categorization models, perceivers can employ two processes: they either treat other people as individuals (individuation) or as members of social groups (social categorization). Second, according to connectionist models, person perception is driven by a single process of spreading activation between mental representations in a learned associative network. We suggest that social categorization and individuation can be conceptualized as different types of inputs to a single (connectionist) process. Furthermore, we implement this idea in computer simulations and show that it can account for an empirical dissociation between social categorization and individuation despite being a single process model. Overall, this work aims to contribute to the coherence and integration of the theoretical and empirical literature on social cognition.},
	number = {2},
	urldate = {2020-07-03},
	journal = {Social Cognition},
	author = {Klapper, André and Dotsch, Ron and van Rooij, Iris and Wigboldus, Daniël H.J.},
	month = mar,
	year = {2018},
	keywords = {connectionism, memory, person perception, social categorization},
	pages = {221--246}
}

@article{thagard_coherence_1998,
	title = {Coherence as constraint satisfaction},
	volume = {22},
	issn = {0364-0213},
	url = {http://www.sciencedirect.com/science/article/pii/S0364021399800330},
	doi = {10.1016/S0364-0213(99)80033-0},
	abstract = {This paper provides a computational characterization of coherence that applies to a wide range of philosophical problems and psychological phenomena. Maximizing coherence is a matter of maximizing satisfaction of a set of positive and negative constraints. After comparing five algorithms for maximizing coherence, we show how our characterization of coherence overcomes traditional philosophical objections about circularity and truth.},
	language = {en},
	number = {1},
	urldate = {2020-07-03},
	journal = {Cognitive Science},
	author = {Thagard, Paul and Verbeurgt, Karsten},
	month = jan,
	year = {1998},
	pages = {1--24}
}

@misc{noauthor_coherence_nodate-2,
	title = {Coherence as constraint satisfaction - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0364021399800330},
	urldate = {2020-07-03}
}

@article{thagard_coherence_nodate,
	title = {Coherence as {Constraint} {Satisfaction}},
	language = {en},
	author = {Thagard, Paul and Verbeurgt, Karsten},
	pages = {24}
}

@article{klapper_social_nodate,
	title = {{SOCIAL} {CATEGORIZATION} {IN} {CONNECTIONIST} {MODELS}: {A} {CONCEPTUAL} {INTEGRATION}},
	abstract = {We present a conceptual integration of two major types of social perception models. First, according to social categorization models, perceivers can employ two processes: they either treat other people as individuals (individuation) or as members of social groups (social categorization). Second, according to connectionist models, person perception is driven by a single process of spreading activation between mental representations in a learned associative network. We suggest that social categorization and individuation can be conceptualized as different types of inputs to a single (connectionist) process. Furthermore, we implement this idea in computer simulations and show that it can account for an empirical dissociation between social categorization and individuation despite being a single process model. Overall, this work aims to contribute to the coherence and integration of the theoretical and empirical literature on social cognition.},
	language = {en},
	author = {Klapper, André and Dotsch, Ron and van Rooij, Iris and Wigboldus, Daniël H J},
	pages = {26}
}

@misc{noauthor_social_nodate,
	title = {Social {Categorization} in {Connectionist} {Models}: {A} {Conceptual} {Integration} {\textbar} {Social} {Cognition}},
	url = {https://guilfordjournals.com/doi/abs/10.1521/soco.2018.36.2.221},
	urldate = {2020-07-03}
}

@techreport{smaldino_how_2020,
	type = {preprint},
	title = {How to translate a verbal theory into a formal model},
	url = {https://osf.io/n7qsh},
	abstract = {Turning verbal theories into formal models is an essential business of a mature science. Here I elaborate on taxonomies of models, provide ten lessons for translating a verbal theory into a formal model, and discuss the specific challenges involved in collaborations between modelers and non-modelers. It's a start.},
	urldate = {2020-07-03},
	institution = {MetaArXiv},
	author = {Smaldino, Paul},
	month = may,
	year = {2020},
	doi = {10.31222/osf.io/n7qsh}
}

@article{szollosi_is_2020-1,
	title = {Is {Preregistration} {Worthwhile}?},
	volume = {24},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(19)30285-2},
	doi = {10.1016/j.tics.2019.11.009},
	language = {English},
	number = {2},
	urldate = {2020-07-03},
	journal = {Trends in Cognitive Sciences},
	author = {Szollosi, Aba and Kellen, David and Navarro, Danielle J. and Shiffrin, Richard and Rooij, Iris van and Zandt, Trisha Van and Donkin, Chris},
	month = feb,
	year = {2020},
	pmid = {31892461},
	note = {Publisher: Elsevier},
	keywords = {inference, preregistration, theory development},
	pages = {94--95}
}

@article{macal_tutorial_2010,
	title = {Tutorial on agent-based modelling and simulation},
	volume = {4},
	issn = {1747-7786},
	url = {https://doi.org/10.1057/jos.2010.3},
	doi = {10.1057/jos.2010.3},
	abstract = {Agent-based modelling and simulation (ABMS) is a relatively new approach to modelling systems composed of autonomous, interacting agents. Agent-based modelling is a way to model the dynamics of complex systems and complex adaptive systems. Such systems often self-organize themselves and create emergent order. Agent-based models also include models of behaviour (human or otherwise) and are used to observe the collective effects of agent behaviours and interactions. The development of agent modelling tools, the availability of micro-data, and advances in computation have made possible a growing number of agent-based applications across a variety of domains and disciplines. This article provides a brief introduction to ABMS, illustrates the main concepts and foundations, discusses some recent applications across a variety of disciplines, and identifies methods and toolkits for developing agent models.},
	language = {en},
	number = {3},
	urldate = {2020-07-03},
	journal = {Journal of Simulation},
	author = {Macal, C M and North, M J},
	month = sep,
	year = {2010},
	pages = {151--162}
}

@book{van_rooij_cognition_2019,
	address = {Cambridge},
	title = {Cognition and {Intractability}: {A} {Guide} to {Classical} and {Parameterized} {Complexity} {Analysis}},
	isbn = {978-1-107-04399-2},
	shorttitle = {Cognition and {Intractability}},
	url = {https://www.cambridge.org/core/books/cognition-and-intractability/2FC21B94CCCFBBD1E11A2D30D4503A23},
	abstract = {Intractability is a growing concern across the cognitive sciences: while many models of cognition can describe and predict human behavior in the lab, it remains unclear how these models can scale to situations of real-world complexity. Cognition and Intractability is the first book to provide an accessible introduction to computational complexity analysis and its application to questions of intractability in cognitive science. Covering both classical and parameterized complexity analysis, it introduces the mathematical concepts and proof techniques that can be used to test one's intuition of (in)tractability. It also describes how these tools can be applied to cognitive modeling to deal with intractability, and its ramifications, in a systematic way. Aimed at students and researchers in philosophy, cognitive neuroscience, psychology, artificial intelligence, and linguistics who want to build a firm understanding of intractability and its implications in their modeling work, it is an ideal resource for teaching or self-study.},
	urldate = {2020-07-03},
	publisher = {Cambridge University Press},
	author = {van Rooij, Iris and Blokpoel, Mark and Kwisthout, Johan and Wareham, Todd},
	year = {2019},
	doi = {10.1017/9781107358331}
}

@article{szollosi_is_2020-2,
	title = {Is {Preregistration} {Worthwhile}?},
	volume = {24},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(19)30285-2},
	doi = {10.1016/j.tics.2019.11.009},
	language = {English},
	number = {2},
	urldate = {2020-07-03},
	journal = {Trends in Cognitive Sciences},
	author = {Szollosi, Aba and Kellen, David and Navarro, Danielle J. and Shiffrin, Richard and Rooij, Iris van and Zandt, Trisha Van and Donkin, Chris},
	month = feb,
	year = {2020},
	pmid = {31892461},
	note = {Publisher: Elsevier},
	keywords = {inference, preregistration, theory development},
	pages = {94--95}
}

@article{milkowski_replicability_2018,
	title = {Replicability or reproducibility? {On} the replication crisis in computational neuroscience and sharing only relevant detail},
	volume = {45},
	issn = {1573-6873},
	shorttitle = {Replicability or reproducibility?},
	url = {https://doi.org/10.1007/s10827-018-0702-z},
	doi = {10.1007/s10827-018-0702-z},
	abstract = {Replicability and reproducibility of computational models has been somewhat understudied by “the replication movement.” In this paper, we draw on methodological studies into the replicability of psychological experiments and on the mechanistic account of explanation to analyze the functions of model replications and model reproductions in computational neuroscience. We contend that model replicability, or independent researchers' ability to obtain the same output using original code and data, and model reproducibility, or independent researchers' ability to recreate a model without original code, serve different functions and fail for different reasons. This means that measures designed to improve model replicability may not enhance (and, in some cases, may actually damage) model reproducibility. We claim that although both are undesirable, low model reproducibility poses more of a threat to long-term scientific progress than low model replicability. In our opinion, low model reproducibility stems mostly from authors' omitting to provide crucial information in scientific papers and we stress that sharing all computer code and data is not a solution. Reports of computational studies should remain selective and include all and only relevant bits of code.},
	language = {en},
	number = {3},
	urldate = {2020-07-03},
	journal = {Journal of Computational Neuroscience},
	author = {Miłkowski, Marcin and Hensel, Witold M. and Hohol, Mateusz},
	month = dec,
	year = {2018},
	pages = {163--172}
}

@article{cooper_implementations_2014,
	title = {Implementations are not specifications: {Specification}, replication and experimentation in computational cognitive modeling},
	volume = {27},
	issn = {13890417},
	shorttitle = {Implementations are not specifications},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1389041713000314},
	doi = {10.1016/j.cogsys.2013.05.001},
	abstract = {Contemporary methods of computational cognitive modeling have recently been criticized by Addyman and French (2012) on the grounds that they have not kept up with developments in computer technology and human–computer interaction. They present a manifesto for change according to which, it is argued, modelers should devote more eﬀort to making their models accessible, both to nonmodelers (with an appropriate easy-to-use user interface) and modelers alike. We agree that models, like data, should be freely available according to the normal standards of science, but caution against confusing implementations with speciﬁcations. Models may embody theories, but they generally also include implementation assumptions. Cognitive modeling methodology needs to be sensitive to this. We argue that speciﬁcation, replication and experimentation are methodological approaches that can address this issue.},
	language = {en},
	urldate = {2020-07-03},
	journal = {Cognitive Systems Research},
	author = {Cooper, Richard P. and Guest, Olivia},
	month = mar,
	year = {2014},
	pages = {42--49}
}

@article{guest_how_2020,
	title = {How computational modeling can force theory building in psychological science},
	url = {https://psyarxiv.com/rybh9/},
	doi = {10.31234/osf.io/rybh9},
	abstract = {Psychology endeavors to develop theories of human capacities and behaviors based on a variety of methodologies and dependent measures. We argue that one of the most divisive factors in our field is whether researchers choose to employ computational modeling of theories (over and above data) during the scientific inference process. Modeling is undervalued, yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us towards better science by forcing us to conceptually analyze, specify, and formalise intuitions which otherwise remain unexamined — what we dub “open theory”. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Herein, we present scientific inference in psychology as a path function, where each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability “crises” and persistent failure at coherent theory-building. This is because without formal modelling we lack open and transparent theorising. We also explain how to formalise, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
	urldate = {2020-07-03},
	author = {Guest, Olivia and Martin, Andrea E.},
	month = feb,
	year = {2020},
	note = {Publisher: PsyArXiv}
}

@article{devezer_case_2020,
	title = {The case for formal methodology in scientific reform},
	url = {http://biorxiv.org/content/early/2020/04/28/2020.04.26.048306.abstract},
	doi = {10.1101/2020.04.26.048306},
	abstract = {Current attempts at methodological reform in sciences come in response to an overall lack of rigor in methodological and scientific practices in experimental sciences. However, some of these reform attempts suffer from the same mistakes and over-generalizations they purport to address. Considering the costs of allowing false claims to become canonized, we argue for more rigor and nuance in methodological reform. By way of example, we present a formal analysis of three common claims in the metascientific literature: (a) that reproducibility is the cornerstone of science; (b) that data must not be used twice in any analysis; and (c) that exploratory projects are characterized by poor statistical practice. We show that none of these three claims are correct in general and we explore when they do and do not hold.Competing Interest StatementThe authors have declared no competing interest.},
	journal = {bioRxiv},
	author = {Devezer, Berna and Navarro, Danielle J. and Vandekerckhove, Joachim and Buzbas, Erkan Ozge},
	month = jan,
	year = {2020},
	pages = {2020.04.26.048306}
}

@article{hertwig_constructbehavior_2018,
	title = {The construct–behavior gap and the description–experience gap: {Comment} on {Regenwetter} and {Robinson} (2017).},
	volume = {125},
	issn = {1939-1471, 0033-295X},
	shorttitle = {The construct–behavior gap and the description–experience gap},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/rev0000121},
	doi = {10.1037/rev0000121},
	abstract = {Regenwetter and Robinson (2017) discuss a challenging construct– behavior gap in psychological research. It can emerge when testing hypotheses that pertain to a theoretical construct (e.g., preferences) on the basis of observed behavior (e.g., actual choices). The problem is that the different heuristic methods that are sometimes used to link overt choices to covert preferences may ignore heterogeneity between and within individuals, rendering inferences drawn from choices to preferences invalid. Regenwetter and Robinson’s remedy is to make heterogeneity an explicit part of the theory. They illustrate the problem and a remedy to it with the description– experience gap (D-E gap), the systematic gap in choices based on described versus ‘experienced’ probabilities. We welcome their sophisticated reanalysis of some early data sets, which, by taking heterogeneity into account, finds strong evidence for a D-E gap in probability weighting. Yet we see three issues with the remedy, which we likewise highlight using the D-E gap. First, the D-E gap cannot be reduced solely to probability weighting but rather unfolds across several different psychological constructs suggesting that part of the construct– behavior gap may stem from trying to reduce multidimensional behavior to a single construct. Second, the authors’ modeling of heterogeneity leaves aside the heterogeneity of people’s sampled experience in decisions from experience, which highlights the importance of also considering the potential causes of heterogeneity. Third, we identify potential sources of heterogeneity in choice behavior that go beyond probabilistic responses and preferences and advocate for a pluralistic approach to modeling it. Last but not least, we emphasize that, notwithstanding the importance of rigor and logical coherence in scientific theories, simplifications and (false) generalizations are indispensable in the pursuit of scientific knowledge.},
	language = {en},
	number = {5},
	urldate = {2020-04-26},
	journal = {Psychological Review},
	author = {Hertwig, Ralph and Pleskac, Timothy J.},
	month = oct,
	year = {2018},
	pages = {844--849}
}

@misc{noauthor_researchgate_nodate,
	title = {{ResearchGate}},
	url = {https://www.researchgate.net/publication/315947342_The_Construct-Behavior_Gap_in_Behavioral_Decision_Research_A_Challenge_Beyond_Replicability/link/59259af1aca27295a8e8acfc/download},
	urldate = {2020-04-26}
}

@article{regenwetter_constructbehavior_2017,
	title = {The construct–behavior gap in behavioral decision research: {A} challenge beyond replicability},
	volume = {124},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	shorttitle = {The construct–behavior gap in behavioral decision research},
	doi = {10.1037/rev0000067},
	abstract = {Behavioral decision research compares theoretical constructs like preferences to behavior such as observed choices. Three fairly common links from constructs to behavior are (1) to tally, across participants and decision problems, the number of choices consistent with one predicted pattern of pairwise preferences; (2) to compare what most people choose in each decision problem against a predicted preference pattern; or (3) to enumerate the decision problems in which two experimental conditions generate a 1-sided significant difference in choice frequency ‘consistent’ with the theory. Although simple, these theoretical links are heuristics. They are subject to well-known reasoning fallacies, most notably the fallacy of sweeping generalization and the fallacy of composition. No amount of replication can alleviate these fallacies. On the contrary, reiterating logically inconsistent theoretical reasoning over and again across studies obfuscates science. As a case in point, we consider pairwise choices among simple lotteries and the hypotheses of overweighting or underweighting of small probabilities, as well as the description–experience gap. We discuss ways to avoid reasoning fallacies in bridging the conceptual gap between hypothetical constructs, such as, for example, “overweighting” to observable pairwise choice data. Although replication is invaluable, successful replication of hard-to-interpret results is not. Behavioral decision research stands to gain much theoretical and empirical clarity by spelling out precise and formally explicit theories of how hypothetical constructs translate into observable behavior. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	number = {5},
	journal = {Psychological Review},
	author = {Regenwetter, Michel and Robinson, Maria M.},
	year = {2017},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Choice Behavior, Decision Making, Experimental Replication, Preferences, Probability, Reasoning},
	pages = {533--550}
}

@book{marr_vision_1982,
	address = {New York},
	title = {Vision: a computational investigation into the human representation and processing of visual information},
	shorttitle = {Vision},
	language = {en},
	author = {Marr, David},
	year = {1982},
	keywords = {Data processing, Human information processing, Mathematical models, Vision}
}

@book{read_connectionist_1998,
	title = {Connectionist {Models} of {Social} {Reasoning} and {Social} {Behavior}},
	isbn = {978-0-8058-2216-8},
	abstract = {Although neural network models have had a dramatic impact on the cognitive and brain sciences, social psychology has remained largely unaffected by this intellectual explosion. The first to apply neural network models to social phenomena, this book includes chapters by nearly all of the individuals currently working in this area. Bringing these various approaches together in one place, it allows readers to appreciate the breadth of these approaches, as well as the theoretical commonality of many of these models.  The contributors address a number of central issues in social psychology and show how these kinds of models provide insight into many classic issues. Many chapters hint that this approach provides the seeds of a theoretical integration that the field has lacked. Each chapter discusses an explicit connectionist model of a central problem in social psychology. Since many of the contributors either use a standard architecture or provide a computer program, interested readers, with a little work, should be able to implement their own variations of models.  Chapters are devoted to the following topics and models: * the learning and application of social categories and stereotypes; * causal reasoning, social explanation, and person perception; * personality and social behavior; * classic dissonance phenomena; and * belief change and the coherence of large scale belief systems.},
	language = {en},
	publisher = {Psychology Press},
	author = {Read, Stephen J. and Miller, Lynn C.},
	year = {1998},
	keywords = {Psychology / Social Psychology}
}

@book{cummins_nature_1985,
	title = {The {Nature} of {Psychological} {Explanation}},
	abstract = {In exploring the nature of psychological explanation, this book looks at how psychologists theorize about the human ability to calculate, to speak a language and the like. It shows how good theorizing explains or tries to explain such abilities as perception and cognition. It recasts the familiar explanations of "intelligence" and "cognitive capacity" as put forward by philosophers such as Fodor, Dennett, and others in terms of a theory of explanation that makes established doctrine more intelligible to professionals and their students. In particular, the book shows that vestigial adherence to the positivists' D-N model has distorted the view of philosophers of science about what psychologists (and biologists) do and has masked the real nature of explanation. Major sections in the book cover Analysis and Subsumption; Functional Analysis; Understanding Cognitive Capacities; and Historical Reflections.A Bradford Book.},
	language = {en},
	publisher = {MIT Press},
	author = {Cummins, Robert},
	year = {1985}
}

@book{knuth_art_1968,
	title = {The {Art} of {Computer} {Programming}: {Sorting} and {Searching}},
	isbn = {978-0-201-03803-3},
	shorttitle = {The {Art} of {Computer} {Programming}},
	abstract = {Finally, after a wait of more than thirty-five years, the first part of Volume 4 is at last ready for publication. Check out the boxed set that brings together Volumes 1 - 4A in one elegant case, and offers the purchaser a \$50 discount off the price of buying the four volumes individually. The Art of Computer Programming, Volumes 1-4A Boxed Set, 3/e ISBN: 0321751043},
	language = {en},
	publisher = {Addison-Wesley Publishing Company},
	author = {Knuth, Donald Ervin},
	year = {1968}
}

@incollection{cummins_how_2000,
	title = {How does it work?" versus" what are the laws?": {Two} conceptions of psychological explanation},
	booktitle = {Explanation and cognition},
	publisher = {MIT Press},
	author = {Cummins, Robert},
	year = {2000},
	note = {Frank C. Keil, Robert Andrew Wilson (Eds)},
	pages = {117--144}
}

@article{ross_intuitive_1977,
	title = {The intuitive psychologist and his [sic] shortcomings: {Distortions} in the attribution process},
	volume = {10},
	shorttitle = {The {Intuitive} {Psychologist} {And} {His} {Shortcomings}},
	doi = {10.1016/S0065-2601(08)60357-3},
	abstract = {Attribution theory is concerned with the attempts of ordinary people to understand the causes and implications of the events they witness. It deals with the “naive psychology” of the “man in the street” as he interprets his own behaviors and the actions of others. For man—in the perspective of attribution theory—is an intuitive psychologist who seeks to explain behavior and draw inferences about actors and their environments. To better understand the perceptions and actions of this intuitive scientist, his methods must be explored. The sources of oversight, error, or bias in his assumptions and procedures may have serious consequences, both for the lay psychologist himself and for the society that he builds and perpetuates. These shortcomings, explored from the vantage point of contemporary attribution theory, are the focus of the chapter. The logical or rational schemata employed by intuitive psychologists and the sources of bias in their attempts at understanding, predicting, and controlling the events that unfold around them are considered. Attributional biases in the psychology of prediction, perseverance of social inferences and social theories, and the intuitive psychologist's illusions and insights are described.},
	language = {en},
	journal = {Advances in Experimental Social Psychology},
	author = {Ross, Lee},
	editor = {Berkowitz, Leonard},
	month = jan,
	year = {1977},
	pages = {173--220}
}

@article{blokpoel_computational-level_2013,
	title = {A computational-level explanation of the speed of goal inference},
	volume = {57},
	issn = {0022-2496},
	url = {http://www.sciencedirect.com/science/article/pii/S0022249613000515},
	doi = {10.1016/j.jmp.2013.05.006},
	abstract = {The ability to understand the goals that drive another person’s actions is an important social and cognitive skill. This is no trivial task, because any given action may in principle be explained by different possible goals (e.g., one may wave ones arm to hail a cab or to swat a mosquito). To select which goal best explains an observed action is a form of abduction. To explain how people perform such abductive inferences, Baker, Tenenbaum, and Saxe (2007) proposed a computational-level theory that formalizes goal inference as Bayesian inverse planning (BIP). It is known that general Bayesian inference–be it exact or approximate–is computationally intractable (NP-hard). As the time required for computationally intractable computations grows excessively fast when scaled from toy domains to the real world, it seems that such models cannot explain how humans can perform Bayesian inferences quickly in real world situations. In this paper we investigate how the BIP model can nevertheless explain how people are able to make goal inferences quickly. The approach that we propose builds on taking situational constraints explicitly into account in the computational-level model. We present a methodology for identifying situational constraints that render the model tractable. We discuss the implications of our findings and reflect on how the methodology can be applied to alternative models of goal inference and Bayesian models in general.},
	language = {en},
	number = {3},
	urldate = {2020-04-09},
	journal = {Journal of Mathematical Psychology},
	author = {Blokpoel, Mark and Kwisthout, Johan and van der Weide, Theo P. and Wareham, Todd and van Rooij, Iris},
	month = jun,
	year = {2013},
	keywords = {Abduction, Computational complexity, Fixed-parameter tractability, Goal inference, Intractability, Inverse planning, NP-hard},
	pages = {117--133}
}

@incollection{thagard_making_1998,
	title = {Making sense of people: {Coherence} mechanisms},
	url = {http://cogprints.org/669/1/Making_Sense.html},
	booktitle = {Connectionist models of social reasoning and social behaviour.},
	publisher = {Hillsdale, NJ: Erlbaum.},
	author = {Thagard, Paul and Kunda, Ziva},
	year = {1998}
}
@misc{noauthor_makingsense_nodate,
	title = {Making.{Sense}},
	url = {http://cogprints.org/669/1/Making_Sense.html},
	urldate = {2020-04-09}
}

@article{blokpoel_sculpting_2018,
	title = {Sculpting computational-level models},
	volume = {10},
	copyright = {© 2017 Cognitive Science Society, Inc.},
	issn = {1756-8765},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12282},
	doi = {10.1111/tops.12282},
	abstract = {In this commentary, I advocate for strict relations between Marr's levels of analysis. Under a strict relationship, each level is exactly implemented by the subordinate level. This yields two benefits. First, it brings consistency for multilevel explanations. Second, similar to how a sculptor chisels away superfluous marble, a modeler can chisel a computational-level model by applying constraints. By sculpting the model, one restricts the (potentially infinitely large) set of possible algorithmic- and implementational-level theories.},
	language = {en},
	number = {3},
	urldate = {2020-04-07},
	journal = {Topics in Cognitive Science},
	author = {Blokpoel, Mark},
	year = {2018},
	keywords = {Computational level, Marr's levels, Philosophy of science, Top-down modeling},
	pages = {641--648}
}

@article{otworowska_demons_2018,
	title = {Demons of ecological rationality},
	volume = {42},
	copyright = {Copyright © 2017 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12530},
	doi = {10.1111/cogs.12530},
	language = {en},
	number = {3},
	urldate = {2020-04-07},
	journal = {Cognitive Science},
	author = {Otworowska, Maria and Blokpoel, Mark and Sweers, Marieke and Wareham, Todd and van Rooij, Iris},
	year = {2018},
	keywords = {Adaptive toolbox, Fast-and-frugal heuristics, Intractability, NP-hard, Resource-bounded rationality},
	pages = {1057--1066}
}

@article{van_rooij_tractable_2008,
	title = {The {Tractable} {Cognition} thesis},
	volume = {32},
	copyright = {2008 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	doi = {10.1080/03640210801897856},
	abstract = {The recognition that human minds/brains are finite systems with limited resources for computation has led some researchers to advance the Tractable Cognition thesis: Human cognitive capacities are constrained by computational tractability. This thesis, if true, serves cognitive psychology by constraining the space of computational-level theories of cognition. To utilize this constraint, a precise and workable definition of “computational tractability” is needed. Following computer science tradition, many cognitive scientists and psychologists define computational tractability as polynomial-time computability, leading to the P-Cognition thesis. This article explains how and why the P-Cognition thesis may be overly restrictive, risking the exclusion of veridical computational-level theories from scientific investigation. An argument is made to replace the P-Cognition thesis by the FPT-Cognition thesis as an alternative formalization of the Tractable Cognition thesis (here, FPT stands for fixed-parameter tractable). Possible objections to the Tractable Cognition thesis, and its proposed formalization, are discussed, and existing misconceptions are clarified.},
	language = {en},
	number = {6},
	urldate = {2020-04-07},
	journal = {Cognitive Science},
	author = {van Rooij, Iris},
	year = {2008},
	keywords = {Cognitive modeling, Complexity theory, Computational-level theory, Constraint satisfaction, Intractability, NP-hard, Philosophy of computation, Philosophy of mind},
	pages = {939--984}
}

@article{mitchell_mentalizing_2006,
	title = {Mentalizing and {Marr}: {An} information processing approach to the study of social cognition},
	volume = {1079},
	issn = {00068993},
	shorttitle = {Mentalizing and {Marr}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0006899306000072},
	doi = {10.1016/j.brainres.2005.12.113},
	abstract = {To interact successfully, individuals must not only recognize one another as intentional agents driven primarily by internal mental states, but also possess a system for making reliable and useful inferences about the nature of those beliefs, feelings, goals, and dispositions. The ability to make such mental state inferences (i.e., to mentalize or mindread) is the central accomplishment of human social cognition. The present article suggests that our understanding of how humans go about making mental state inferences will benefit from treating social cognition primarily as an information processing system that comprises a set of mechanisms for elaborating more basic social information into an understanding of another's mind. Following Marr's [Marr, D., 1982. Vision. W. H. Freeman, San Francisco, CA] framework for the study of such information processing systems, I suggest that questions about social cognition might profitably be asked at three levels –computation, algorithm, and implementation – and outline a number of ways in which a description of social cognition at the middle level (i.e., the step-by-step processes that give rise to mental state inferences) can be informed by analysis at the other two.},
	language = {en},
	number = {1},
	urldate = {2020-04-07},
	journal = {Brain Research},
	author = {Mitchell, Jason P.},
	month = mar,
	year = {2006},
	pages = {66--75}
}

@book{thagard_cognitive_2012,
	title = {The {Cognitive} {Science} of {Science}: {Explanation}, {Discovery}, and {Conceptual} {Change}},
	isbn = {978-0-262-30097-1},
	shorttitle = {The {Cognitive} {Science} of {Science}},
	abstract = {A cognitive science perspective on scientific development, drawing on philosophy, psychology, neuroscience, and computational modeling.Many disciplines, including philosophy, history, and sociology, have attempted to make sense of how science works. In this book, Paul Thagard examines scientific development from the interdisciplinary perspective of cognitive science. Cognitive science combines insights from researchers in many fields: philosophers analyze historical cases, psychologists carry out behavioral experiments, neuroscientists perform brain scans, and computer modelers write programs that simulate thought processes.Thagard develops cognitive perspectives on the nature of explanation, mental models, theory choice, and resistance to scientific change, considering disbelief in climate change as a case study. He presents a series of studies that describe the psychological and neural processes that have led to breakthroughs in science, medicine, and technology. He shows how discoveries of new theories and explanations lead to conceptual change, with examples from biology, psychology, and medicine. Finally, he shows how the cognitive science of science can integrate descriptive and normative concerns; and he considers the neural underpinnings of certain scientific concepts.},
	language = {en},
	publisher = {MIT Press},
	author = {Thagard, Paul},
	month = apr,
	year = {2012},
	note = {Google-Books-ID: HrJIV19\_nZYC},
	keywords = {Psychology / Cognitive Psychology \& Cognition, Science / Philosophy \& Social Aspects}
}

@article{houwer_levels_nodate,
	title = {Levels of {Analysis} in {Social} {Psychology}},
	language = {en},
	author = {Houwer, Jan De and Moors, Agnes},
	pages = {30}
}

@incollection{de_houwer_levels_2015,
	address = {New York, NY, US},
	title = {Levels of analysis in social psychology},
	isbn = {978-1-4625-1848-7 978-1-4625-1852-4},
	abstract = {Like many aspects of human behavior, scientific research is a goal directed activity. Hence, to understand scientific behavior, we need to understand the goals that drive scientists. Scientific goals first of all refer to an object that is under investigation. One could, for instance, argue that social psychology aims at understanding social behavior. Because many questions can be asked about any single object a scientific goal can also specify the question that is asked about that object. For instance, social cognition researchers are specifically interested in the mental processes that underlie social behavior, whereas social neuroscientists might be interested primarily in the neural processes that underlie social behavior. In the present, chapter we focus on yet another way in which scientific goals differ: the level of analysis at which the scientific question is analyzed. Even a single question about a single object can be answered at different levels. We illustrate this point in the context of social cognition research. In doing so, we also clarify the way in which social cognition research is related to other approaches in social psychology, including functional and neuroscience approaches. This chapter is based on the influential ideas of David Marr about levels of analyses in cognitive psychology. In this chapter, we extend Marr's ideas by providing a more fine-grained analysis of the different levels and how these levels relate to each other. We specifically illustrate these ideas in the context of social psychology. We hope that reading this chapter will help researchers to make explicit the scientific goals that drive their research. Doing so not only sheds light on scientific practice but can also help facilitate research by exposing false scientific debates and revealing links between seemingly unrelated or contradictory lines of research. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	booktitle = {Theory and explanation in social psychology},
	publisher = {Guilford Press},
	author = {De Houwer, Jan and Moors, Agnes},
	year = {2015},
	keywords = {Cognitive Psychology, Goals, Logical Thinking, Psychological Theories, Social Behavior, Social Cognition, Social Psychology},
	pages = {24--40}
}

@article{rich_naturalism_2019,
	title = {Naturalism, tractability and the adaptive toolbox},
	issn = {1573-0964},
	url = {https://doi.org/10.1007/s11229-019-02431-2},
	doi = {10.1007/s11229-019-02431-2},
	abstract = {Many compelling examples have recently been provided in which people can achieve impressive epistemic success, e.g. draw highly accurate inferences, by using simple heuristics and very little information. This is possible by taking advantage of the features of the environment. The examples suggest an easy and appealing naturalization of rationality: on the one hand, people clearly can apply simple heuristics, and on the other hand, they intuitively ought do so when this brings them high accuracy at little cost.. The ‘ought-can’ principle is satisfied, and rationality is meaningfully normative. We show, however, that this naturalization program is endangered by a computational wrinkle in the adaptation process taken to be responsible for this heuristics-based (‘ecological’) rationality: for the adaptation process to guarantee even minimal rationality, it requires astronomical computational resources, making the problem intractable. We consider various plausible auxiliary assumptions in attempt to remove this obstacle, and show that they do not succeed; intractability is a robust property of adaptation. We discuss the implications of our findings for the project of naturalizing rationality.},
	language = {en},
	urldate = {2020-03-31},
	journal = {Synthese},
	author = {Rich, Patricia and Blokpoel, Mark and de Haan, Ronald and Otworowska, Maria and Sweers, Marieke and Wareham, Todd and van Rooij, Iris},
	month = oct,
	year = {2019}
}

@article{bechtel_non-redundant_2015,
	title = {The {Non}-{Redundant} {Contributions} of {Marr}'s {Three} {Levels} of {Analysis} for {Explaining} {Information}-{Processing} {Mechanisms}},
	volume = {7},
	copyright = {Copyright © 2015 Cognitive Science Society, Inc.},
	issn = {1756-8765},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12141},
	doi = {10.1111/tops.12141},
	abstract = {Are all three of Marr's levels needed? Should they be kept distinct? We argue for the distinct contributions and methodologies of each level of analysis. It is important to maintain them because they provide three different perspectives required to understand mechanisms, especially information-processing mechanisms. The computational perspective provides an understanding of how a mechanism functions in broader environments that determines the computations it needs to perform (and may fail to perform). The representation and algorithmic perspective offers an understanding of how information about the environment is encoded within the mechanism and what are the patterns of organization that enable the parts of the mechanism to produce the phenomenon. The implementation perspective yields an understanding of the neural details of the mechanism and how they constrain function and algorithms. Once we adequately characterize the distinct role of each level of analysis, it is fairly straightforward to see how they relate.},
	language = {en},
	number = {2},
	urldate = {2019-08-25},
	journal = {Topics in Cognitive Science},
	author = {Bechtel, William and Shagrir, Oron},
	year = {2015},
	keywords = {Computational level, Environmental context, Marr, Mechanistic explanation, Representation and algorithmic level},
	pages = {312--322}
}

@article{meehl_appraising_1990,
	title = {Appraising and {Amending} {Theories}: {The} {Strategy} of {Lakatosian} {Defense} and {Two} {Principles} that {Warrant} {It}},
	volume = {1},
	issn = {1047-840X, 1532-7965},
	shorttitle = {Appraising and {Amending} {Theories}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0102_1},
	doi = {10.1207/s15327965pli0102_1},
	language = {en},
	number = {2},
	urldate = {2019-08-25},
	journal = {Psychological Inquiry},
	author = {Meehl, Paul E.},
	month = apr,
	year = {1990},
	pages = {108--141}
}

@misc{noauthor_valiant_nodate,
	title = {Valiant, {L}. {G}. {A} theory of the learnable. {Commun}. {ACM} 27, 1134-1142 (1984). at {DuckDuckGo}},
	url = {https://duckduckgo.com/?q=Valiant%2C+L.+G.+A+theory+of+the+learnable.+Commun.+ACM+27%2C+1134%E2%80%931142+(1984).&t=osx&ia=web},
	urldate = {2019-07-19}
}

@article{ben-david_learnability_2019,
	title = {Learnability can be undecidable},
	volume = {1},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-018-0002-3},
	doi = {10.1038/s42256-018-0002-3},
	abstract = {Not all mathematical questions can be resolved, according to Gödel’s famous incompleteness theorems. It turns out that machine learning can be vulnerable to undecidability too, as is illustrated with an example problem where learnability cannot be proved nor refuted.},
	language = {En},
	number = {1},
	urldate = {2019-07-18},
	journal = {Nature Machine Intelligence},
	author = {Ben-David, Shai and Hrubeš, Pavel and Moran, Shay and Shpilka, Amir and Yehudayoff, Amir},
	month = jan,
	year = {2019},
	pages = {44}
}

@article{valiant_evolvability_2009,
	title = {Evolvability},
	volume = {56},
	issn = {00045411},
	url = {http://portal.acm.org/citation.cfm?doid=1462153.1462156},
	doi = {10.1145/1462153.1462156},
	language = {en},
	number = {1},
	urldate = {2019-07-18},
	journal = {Journal of the ACM},
	author = {Valiant, Leslie G.},
	month = jan,
	year = {2009},
	pages = {1--21}
}

@article{gold_limiting_1965,
	title = {Limiting {Recursion}},
	volume = {30},
	issn = {0022-4812},
	url = {https://www.jstor.org/stable/2270580},
	doi = {10.2307/2270580},
	number = {1},
	urldate = {2019-07-18},
	journal = {The Journal of Symbolic Logic},
	author = {Gold, E. Mark},
	year = {1965},
	pages = {28--48}
}

@article{lu_emergence_2019,
	title = {Emergence of analogy from relation learning},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1814779116},
	doi = {10.1073/pnas.1814779116},
	language = {en},
	number = {10},
	urldate = {2019-06-28},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Lu, Hongjing and Wu, Ying Nian and Holyoak, Keith J.},
	month = mar,
	year = {2019},
	pages = {4176--4181}
}

@article{flis_psychologists_2019,
	title = {Psychologists psychologizing scientific psychology: {An} epistemological reading of the replication crisis},
	volume = {29},
	issn = {0959-3543, 1461-7447},
	shorttitle = {Psychologists psychologizing scientific psychology},
	url = {http://journals.sagepub.com/doi/10.1177/0959354319835322},
	doi = {10.1177/0959354319835322},
	abstract = {In this article, I critically discuss the philosophy and psychology of science that are put forward by psychologists involved in the reform debates centered on the so-called “replication crisis” of the 2010s. Following the historian of psychology Laurence Smith, I describe the psychologists’ conception of the science system and individual psychology of the scientist as an “indigenous epistemology.” By first describing the indigenous epistemology of the reform movement, my aim is to constructively criticize it by making explicit how psychologists psychologize scientific psychology, and pointing to where such psychologizing needs more conceptual work, especially when it uses the work of philosophers of science. In their writing, the reformers tentatively subscribe to various positions on ways of knowing and functioning of the science system which exhibit fundamental inconsistencies. I suggest some ways for improving and deepening the discussion of epistemological positions that are taken in the replication crisis debates.},
	language = {en},
	number = {2},
	urldate = {2019-05-25},
	journal = {Theory \& Psychology},
	author = {Flis, Ivan},
	month = apr,
	year = {2019},
	pages = {158--181}
}

@article{todd_bounding_2003,
	title = {Bounding rationality to the world},
	volume = {24},
	issn = {01674870},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167487002002003},
	doi = {10.1016/S0167-4870(02)00200-3},
	abstract = {Simon proposed that human rationality is bounded by both internal (mental) and external (environmental) constraints. Traditionally, these constraints have been seen as independent, leading to a notion of bounded rationality that is either the attempt to do as well as possible given the demands of the world – the notion of optimization under constraints – or as the suboptimal outcome of the limited cognitive system – the realm of cognitive illusions. But there is a third possibility, following SimonÕs original conception: rather than being unrelated, the two sets of bounds may ﬁt together like the blades in a pair of scissors. The mind can take advantage of this ﬁt to make good decisions, by using mental mechanisms whose internal structure exploits the external information structures available in the environment. In this paper we lay out a research program for studying simple decision heuristics of this sort that expands on SimonÕs own search for mechanisms of bounded rationality. We then illustrate how these heuristics can make accurate decisions in appropriate environments, and present detailed examples of two heuristics inspired by SimonÕs ideas on recognition-based processing and satisﬁcing in sequential search.},
	language = {en},
	number = {2},
	urldate = {2019-04-04},
	journal = {Journal of Economic Psychology},
	author = {Todd, Peter M and Gigerenzer, Gerd},
	month = apr,
	year = {2003},
	pages = {143--165}
}

@misc{press_bounded_nodate,
	title = {Bounded {Rationality}},
	url = {https://mitpress.mit.edu/books/bounded-rationality},
	abstract = {In a complex and uncertain world, humans and animals make decisions under the constraints of limited knowledge, resources, and time. Yet models of rational decision making in economics, cognitive science, biology, and other fields largely ignore these real constraints and instead assume agents with perfect information and unlimited time. About forty years ago, Herbert Simon challenged this view with his notion of "bounded rationality." Today, bounded rationality has become a fashionable term used for disparate views of reasoning.This book promotes bounded rationality as the key to understanding how real people make decisions. Using the concept of an "adaptive toolbox," a repertoire of fast and frugal rules for decision making under uncertainty, it attempts to impose more order and coherence on the idea of bounded rationality. The contributors view bounded rationality neither as optimization under constraints nor as the study of people's reasoning fallacies. The strategies in the adaptive toolbox dispense with optimization and, for the most part, with calculations of probabilities and utilities. The book extends the concept of bounded rationality from cognitive tools to emotions; it analyzes social norms, imitation, and other cultural tools as rational strategies; and it shows how smart heuristics can exploit the structure of environments.},
	language = {en},
	urldate = {2019-04-04},
	journal = {The MIT Press},
	author = {Press, The MIT}
}

@article{barrett_enzymatic_2005,
	title = {Enzymatic {Computation} and {Cognitive} {Modularity}},
	volume = {20},
	issn = {0268-1064, 1468-0017},
	url = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00285.x},
	doi = {10.1111/j.0268-1064.2005.00285.x},
	abstract = {Currently, there is widespread skepticism that higher cognitive processes, given their apparent flexibility and globality, could be carried out by specialized computational devices, or modules. This skepticism is largely due to Fodor’s influential definition of modularity. From the rather flexible catalogue of possible modular features that Fodor originally proposed has emerged a widely held notion of modules as rigid, informationally encapsulated devices that accept highly local inputs and whose operations are insensitive to context. It is a mistake, however, to equate such features with computational devices in general and therefore to assume, as Fodor does, that higher cognitive processes must be non-computational. Of the many possible non-Fodorean architectures, one is explored here that offers possible solutions to computational problems faced by conventional modular systems: an ‘enzymatic’ architecture. Enzymes are computational devices that use lock-and-key template matching to identify relevant information (substrates), which is then operated upon and returned to a common pool for possible processing by other devices. Highly specialized enzymes can operate together in a common pool of information that is not pre-sorted by information type. Moreover, enzymes can use molecular ‘tags’ to regulate the operations of other devices and to change how particular substrates are construed and operated upon, allowing for highly interactive, context-specific processing. This model shows how specialized, modular processing can occur in an open system, and suggests that skepticism about modularity may largely be due to failure to consider alternatives to the standard model.},
	language = {en},
	number = {3},
	urldate = {2018-04-22},
	journal = {Mind and Language},
	author = {Barrett, H. Clark},
	month = jun,
	year = {2005},
	pages = {259--287}
}

@article{barrett_enzymatic_2005-1,
	title = {Enzymatic {Computation} and {Cognitive} {Modularity}},
	volume = {20},
	issn = {0268-1064, 1468-0017},
	url = {http://doi.wiley.com/10.1111/j.0268-1064.2005.00285.x},
	doi = {10.1111/j.0268-1064.2005.00285.x},
	abstract = {Currently, there is widespread skepticism that higher cognitive processes, given their apparent flexibility and globality, could be carried out by specialized computational devices, or modules. This skepticism is largely due to Fodor’s influential definition of modularity. From the rather flexible catalogue of possible modular features that Fodor originally proposed has emerged a widely held notion of modules as rigid, informationally encapsulated devices that accept highly local inputs and whose operations are insensitive to context. It is a mistake, however, to equate such features with computational devices in general and therefore to assume, as Fodor does, that higher cognitive processes must be non-computational. Of the many possible non-Fodorean architectures, one is explored here that offers possible solutions to computational problems faced by conventional modular systems: an ‘enzymatic’ architecture. Enzymes are computational devices that use lock-and-key template matching to identify relevant information (substrates), which is then operated upon and returned to a common pool for possible processing by other devices. Highly specialized enzymes can operate together in a common pool of information that is not pre-sorted by information type. Moreover, enzymes can use molecular ‘tags’ to regulate the operations of other devices and to change how particular substrates are construed and operated upon, allowing for highly interactive, context-specific processing. This model shows how specialized, modular processing can occur in an open system, and suggests that skepticism about modularity may largely be due to failure to consider alternatives to the standard model.},
	language = {en},
	number = {3},
	urldate = {2018-04-22},
	journal = {Mind and Language},
	author = {Barrett, H. Clark},
	month = jun,
	year = {2005},
	pages = {259--287}
}

@article{wooldridge_complexity_2005,
	title = {The complexity of agent design problems: {Determinism} and history dependence},
	volume = {45},
	issn = {1012-2443, 1573-7470},
	shorttitle = {The complexity of agent design problems},
	url = {http://link.springer.com/10.1007/s10472-005-9003-0},
	doi = {10.1007/s10472-005-9003-0},
	language = {en},
	number = {3-4},
	urldate = {2018-04-16},
	journal = {Annals of Mathematics and Artificial Intelligence},
	author = {Wooldridge, Michael and Dunne, Paul E.},
	month = dec,
	year = {2005},
	pages = {343--371}
}

@article{van_gelder_dynamical_1998,
	title = {The dynamical hypothesis in cognitive science},
	volume = {21},
	issn = {0140-525X, 1469-1825},
	url = {http://www.journals.cambridge.org/abstract_S0140525X98001733},
	doi = {10.1017/S0140525X98001733},
	abstract = {According to the dominant computational approach in cognitive science, cognitive agents are digital computers; according to the alternative approach, they are dynamical systems. This target article attempts to articulate and support the dynamical hypothesis. The dynamical hypothesis has two major components: the nature hypothesis (cognitive agents are dynamical systems) and the knowledge hypothesis (cognitive agents can be understood dynamically). A wide range of objections to this hypothesis can be rebutted. The conclusion is that cognitive systems may well be dynamical systems, and only sustained empirical research in cognitive science will determine the extent to which that is true.},
	language = {en},
	number = {05},
	urldate = {2018-04-16},
	journal = {Behavioral and Brain Sciences},
	author = {van Gelder, Tim},
	month = oct,
	year = {1998}
}

@article{sperber_pragmatics_nodate,
	title = {Pragmatics, {Modularity} and {Mind}-reading},
	abstract = {The central problem for pragmatics is that sentence meaning vastly underdetermines speaker’s meaning. The goal of pragmatics is to explain how the gap between sentence meaning and speaker’s meaning is bridged. This paper defends the broadly Gricean view that pragmatic interpretation is ultimately an exercise in mind-reading, involving the inferential attribution of intentions. We argue, however, that the interpretation process does not simply consist in applying general mind-reading abilities to a particular (communicative) domain. Rather, it involves a dedicated comprehension module, with its own special principles and mechanisms. We show how such a metacommunicative module might have evolved, and what principles and mechanisms it might contain.},
	author = {SPERBER, DAN and WILSON, DEIRDRE},
	pages = {32}
}

@misc{noauthor_polynomial-time_nodate,
	title = {Polynomial-{Time} {Algorithms} for {Prime} {Factorization} and {Discrete} {Logarithms} on a {Quantum} {Computer} {\textbar} {SIAM} {Journal} on {Computing} {\textbar} {Vol}. 26, {No}. 5 {\textbar} {Society} for {Industrial} and {Applied} {Mathematics}},
	url = {https://epubs.siam.org/doi/10.1137/S0097539795293172},
	urldate = {2018-04-16}
}

@article{narayanan_quantum_nodate,
	title = {Quantum computing for beginners},
	abstract = {The paper introduces the basic concepts and principles behind quantum computing and examines in detail Shor’s quantum algorithm for factoring very large numbers. Some basic methodological principles and guidelines for constructing quantum algorithms are stated. The aim is not to provide a formal exposition of quantum computing but to identify its novelty and potential use in tackling NP-hard problems.},
	author = {Narayanan, Ajit},
	pages = {12}
}

@book{gigerenzer_heuristics_2011,
	title = {Heuristics},
	isbn = {978-0-19-974428-2},
	url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199744282.001.0001/acprof-9780199744282},
	abstract = {This article provides an overview of recent results on lexicographic, linear, and Bayesian models for paired comparison from a cognitive psychology perspective. Within each class, we distinguish subclasses according to the computational complexity required for parameter setting. We identify the optimal model in each class, where optimality is deﬁned with respect to performance when ﬁtting known data. Although not optimal when ﬁtting data, simple models can be astonishingly accurate when generalizing to new data. A simple heuristic belonging to the class of lexicographic models is Take The Best (Gigerenzer \& Goldstein (1996) Psychol. Rev. 102: 684). It is more robust than other lexicographic strategies which use complex procedures to establish a cue hierarchy. In fact, it is robust due to its simplicity, not despite it. Similarly, Take The Best looks up only a fraction of the information that linear and Bayesian models require; yet it achieves performance comparable to that of models which integrate information. Due to its simplicity, frugality, and accuracy, Take The Best is a plausible candidate for a psychological model in the tradition of bounded rationality. We review empirical evidence showing the descriptive validity of fast and frugal heuristics.},
	urldate = {2018-04-16},
	publisher = {Oxford University Press},
	author = {Gigerenzer, Gerd and Hertwig, Ralph and Pachur, Thorsten},
	month = apr,
	year = {2011},
	doi = {10.1093/acprof:oso/9780199744282.001.0001}
}

@article{markman_structure_2000,
	title = {Structure {Mapping} in the {Comparison} {Process}},
	volume = {113},
	issn = {00029556},
	url = {https://www.jstor.org/stable/1423470?origin=crossref},
	doi = {10.2307/1423470},
	number = {4},
	urldate = {2018-04-16},
	journal = {The American Journal of Psychology},
	author = {Markman, Arthur B. and Gentner, Dedre},
	year = {2000},
	pages = {501}
}

@incollection{haselager_14_2008,
	address = {San Diego},
	series = {Perspectives on {Cognitive} {Science}},
	title = {14 - {A} {Lazy} {Brain}? {Embodied} {Embedded} {Cognition} and {Cognitive} {Neuroscience}},
	shorttitle = {14 - {A} {Lazy} {Brain}?},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080466163000141},
	abstract = {Compared to for instance the E. coli, humans have an exceptionally rich behavioral repertoire that gets applied with great flexibility and sensitivity to environmental conditions. This chapter argues against the received view in cognitive neuroscience, that is, that cognitive systems can display this behavior only by maintaining mental representations of the world on the basis of which plans are made to achieve specific goals. It explains how such a position leads to the problem of computational intractability. It proposes that effective control may be possible for a more tractable, even “lazy,” control system that does not maintain any internal models of the world, assuming that such “lazy” control systems co-evolve with the bodies and environments of organisms. This co-evolution ensures a certain degree of fit between the control system of an organism and its life world.},
	urldate = {2018-04-16},
	booktitle = {Handbook of {Cognitive} {Science}},
	publisher = {Elsevier},
	author = {Haselager, Pim and van Dijk, Jelle and van Rooij, Iris},
	year = {2008},
	doi = {10.1016/B978-0-08-046616-3.00014-1},
	pages = {273--290}
}

@incollection{haselager_14_2008-1,
	address = {San Diego},
	series = {Perspectives on {Cognitive} {Science}},
	title = {14 - {A} {Lazy} {Brain}? {Embodied} {Embedded} {Cognition} and {Cognitive} {Neuroscience}},
	shorttitle = {14 - {A} {Lazy} {Brain}?},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080466163000141},
	abstract = {Compared to for instance the E. coli, humans have an exceptionally rich behavioral repertoire that gets applied with great flexibility and sensitivity to environmental conditions. This chapter argues against the received view in cognitive neuroscience, that is, that cognitive systems can display this behavior only by maintaining mental representations of the world on the basis of which plans are made to achieve specific goals. It explains how such a position leads to the problem of computational intractability. It proposes that effective control may be possible for a more tractable, even “lazy,” control system that does not maintain any internal models of the world, assuming that such “lazy” control systems co-evolve with the bodies and environments of organisms. This co-evolution ensures a certain degree of fit between the control system of an organism and its life world.},
	urldate = {2018-04-16},
	booktitle = {Handbook of {Cognitive} {Science}},
	publisher = {Elsevier},
	author = {Haselager, Pim and van Dijk, Jelle and van Rooij, Iris},
	year = {2008},
	doi = {10.1016/B978-0-08-046616-3.00014-1},
	pages = {273--290}
}

@misc{raggett_https://www.facebook.com/quantummind_2013,
	title = {https://www.facebook.com/{QuantumMind}},
	shorttitle = {https},
	url = {http://quantum-mind.co.uk/gaps-penroses-toiling/},
	abstract = {Gaps in Penrose's Toiling Rick Grush \& Patricia Churchland Philosophy of Dept., University of California, San Diego Journal of Consciousness, 2, No. 1, 1995, pp. 10-29 Keywords:  mathematical truth, unknowable algorithm, quasi-crystals The core part of this article is the Grush and Churchland’s discussion of the soundness of the processes by which mathematical truth is ascertained. The authors say that for convenience they will grant Penrose’s claims that human mathematicians are not using a knowable sound algorithm in exercising mathematical understanding, and thus arriving at ascertainible or unassailable mathematical truths. They also go along with his claim that there is no sound but unknowable algorithm. Instead they concentrate their discussion on the soundness of the brain procedures involved. They basically argue against the soundness of such procedures. They point out, and Penrose agrees with them in saying, that mathematicians sometimes make errors. The authors admit that anyone can make an error while applying a fundamentally sound procedure but they argue that the complexities of mathematics make it hard to distinguish an error of application from an unsound procedure. Therefore they claim that Penrose can only substantiate his claim by specifying procedures that are short enough for it to be easily checked that the application of procedures has been correct. The authors point to the case of the famous 19th century mathematician, Cauchy, who denied the possibility of the existence of infinite sets. The existence of such sets is now a basic part of mathematics as taught to students. The authors argue from this that there are no sound procedures, but only procedures that are usually reliable, or which are useful on a trial and error basis. Penrose replied to Grush and Churchland in the next volume of the Journal of Consciousness Studies. In his reply, he decides to concentrate the argument on the question of Pi 1 sentences, which assert that particular computations, such as Goldbach’s conjecture and the Lagrange theorem do not halt. He considers that these sentences are in principle accessible by human reasoning and insight. In contrast to Grush/Churchlands contention that mathematicians use trial and error and general reliability, Penrose claims that mathematical understanding is more precise than anything in science or philosophy. Penrose accepts that individual mathematicians make errors, but says the point is that there is an argument to be found which gives access to the mathematical truth. The rest of the Grush/Churchland article is a disappointment relative to the reasonably coherent discussion of mathematical truth. As philosophers, they are more plausible in terms of arguments relative to logic and maths than in physics or neuroscience, where Penrose and Hameroff are better placed in terms of scientific knowledge. They appear to waste a lot of time on the proposition attributed to Penrose that quasicrystals are evidence of non-algorithmic physical processes. In fact, Penrose suggested that their relationship might be non-local, rather than non-algorithmic. More to the point, even if there was nothing unusual about the quasi crystals it is not apparent why this would by itself…},
	language = {en-US},
	urldate = {2018-04-16},
	journal = {Quantum Mind},
	author = {Raggett, Simon},
	month = sep,
	year = {2013}
}

@book{gigerenzer_simple_2000,
	address = {Oxford},
	edition = {1 edition},
	title = {Simple {Heuristics} {That} {Make} {Us} {Smart}},
	isbn = {978-0-19-514381-2},
	abstract = {Simple Heuristics That Make Us Smart invites readers to embark on a new journey into a land of rationality that differs from the familiar territory of cognitive science and economics. Traditional views of rationality tend to see decision makers as possessing superhuman powers of reason, limitless knowledge, and all of eternity in which to ponder choices. To understand decisions in the real world, we need a different, more psychologically plausible notion of rationality, and this book provides it. It is about fast and frugal heuristics--simple rules for making decisions when time is pressing and deep thought an unaffordable luxury. These heuristics can enable both living organisms and artificial systems to make smart choices, classifications, and predictions by employing bounded rationality.  But when and how can such fast and frugal heuristics work? Can judgments based simply on one good reason be as accurate as those based on many reasons? Could less knowledge even lead to systematically better predictions than more knowledge? Simple Heuristics explores these questions, developing computational models of heuristics and testing them through experiments and analyses. It shows how fast and frugal heuristics can produce adaptive decisions in situations as varied as choosing a mate, dividing resources among offspring, predicting high school drop out rates, and playing the stock market.  As an interdisciplinary work that is both useful and engaging, this book will appeal to a wide audience. It is ideal for researchers in cognitive psychology, evolutionary psychology, and cognitive science, as well as in economics and artificial intelligence. It will also inspire anyone interested in simply making good decisions.},
	language = {English},
	publisher = {Oxford University Press},
	author = {Gigerenzer, Gerd and Todd, Peter M. and Group, ABC Research},
	month = sep,
	year = {2000}
}

@article{penrose_what_nodate,
	title = {What '{Gaps}'? {Reply} to {Grush} and {Churchland}},
	abstract = {Grush and Churchland (1995) attempt to address aspects of the proposal that we have been making concerning a possible physical mechanism underlying the phenomenon of consciousness. Unfortunately, they employ arguments that are highly misleading and, in some important respects, factually incorrect. Their article ‘Gaps in Penrose’s Toilings’ is addressed specifically at the writings of one of us (Penrose), but since the particular model they attack is one put forward by both of us (Hameroff and Penrose, 1995; 1996), it is appropriate that we both reply; but since our individual remarks refer to different aspects of their criticism we are commenting on their article separately. The logical arguments discussed by Grush and Churchland, and the related physics are answered in Part l by Penrose, largely by pointing out precisely where these arguments have already been treated in detail in Shadows of the Mind (Penrose, 1994). In Part 2, Hameroff replies to various points on the biological side, showing for example how they have seriously misunderstood what they refer to as ‘physiological evidence’ regarding to effects of the drug colchicine. The reply serves also to discuss aspects of our model ‘orchestrated objective reduction in brain microtubules – Orch OR’ which attempts to deal with the serious problems of consciousness more directly and completely than any previous theory.},
	author = {Penrose, Roger and Giles, St and Hameroff, Stuart},
	pages = {18}
}

@misc{noauthor_efficient_nodate,
	title = {Efficient {Parallel} {Algorithms} by {Alan} {Gibbons}, {Wojciech} {Rytter} {\textbar}, {Hardcover} {\textbar} {Barnes} \& {Noble}®},
	url = {https://www.barnesandnoble.com/w/efficient-parallel-algorithms-alan-gibbons/1122585464},
	urldate = {2018-04-16}
}

@article{michael_complexity_2003,
	title = {Complexity {Results} for {Agent} {Design} {Problems}},
	volume = {1},
	abstract = {The Agent Design problem involves determining whether or not it is possible to construct an agent capable of accomplishing a given task in a given environment. The simplest examples of such tasks are where an agent is required to bring about some goal (achievement tasks) or where an agent is required to maintain some invariant condition (maintenance tasks). Previous work has considered the complexity of achievement and maintenance agent design problems for a range of environmental properties. In this paper, we investigate the computational complexity of the agent design problem in three further settings. First, we investigate the issue of tasks that are speciﬁed as Boolean combinations of achievement and maintenance tasks. Second, we investigate the extent to which an agent’s information about the history of the environment in which it operates affects the complexity of the problem: in the bounded agent design problem, an agent is constrained to have a 0, 1, or k {\textgreater} 1 bound on what it is permitted to “remember” about the history of the system. Finally, we investigate the complexity of stochastic agent design problems, where we ask whether there is an agent that has a probability of success at least p.},
	number = {1},
	journal = {ANNALS OF MATHEMATICS},
	author = {Michael, Paul E Dunne and Wooldridge, Laurence Michael},
	year = {2003},
	pages = {18}
}

@article{michael_complexity_2003-1,
	title = {Complexity {Results} for {Agent} {Design} {Problems}},
	volume = {1},
	abstract = {The Agent Design problem involves determining whether or not it is possible to construct an agent capable of accomplishing a given task in a given environment. The simplest examples of such tasks are where an agent is required to bring about some goal (achievement tasks) or where an agent is required to maintain some invariant condition (maintenance tasks). Previous work has considered the complexity of achievement and maintenance agent design problems for a range of environmental properties. In this paper, we investigate the computational complexity of the agent design problem in three further settings. First, we investigate the issue of tasks that are speciﬁed as Boolean combinations of achievement and maintenance tasks. Second, we investigate the extent to which an agent’s information about the history of the environment in which it operates affects the complexity of the problem: in the bounded agent design problem, an agent is constrained to have a 0, 1, or k {\textgreater} 1 bound on what it is permitted to “remember” about the history of the system. Finally, we investigate the complexity of stochastic agent design problems, where we ask whether there is an agent that has a probability of success at least p.},
	number = {1},
	journal = {ANNALS OF MATHEMATICS},
	author = {Michael, Paul E Dunne and Wooldridge, Laurence Michael},
	year = {2003},
	pages = {18}
}

@article{deutsch_quantum_1985,
	title = {Quantum theory, the {Church}–{Turing} principle and the universal quantum computer},
	volume = {400},
	copyright = {Scanned images copyright © 2017, Royal Society},
	issn = {0080-4630, 2053-9169},
	url = {http://rspa.royalsocietypublishing.org/content/400/1818/97},
	doi = {10.1098/rspa.1985.0070},
	abstract = {It is argued that underlying the Church–Turing hypothesis there is an implicit physical assertion. Here, this assertion is presented explicitly as a physical principle: ‘every finitely realizible physical system can be perfectly simulated by a universal model computing machine operating by finite means’. Classical physics and the universal Turing machine, because the former is continuous and the latter discrete, do not obey the principle, at least in the strong form above. A class of model computing machines that is the quantum generalization of the class of Turing machines is described, and it is shown that quantum theory and the 'universal quantum computer’ are compatible with the principle. Computing machines resembling the universal quantum computer could, in principle, be built and would have many remarkable properties not reproducible by any Turing machine. These do not include the computation of non-recursive functions, but they do include ‘quantum parallelism’, a method by which certain probabilistic tasks can be performed faster by a universal quantum computer than by any classical restriction of it. The intuitive explanation of these properties places an intolerable strain on all interpretations of quantum theory other than Everett’s. Some of the numerous connections between the quantum theory of computation and the rest of physics are explored. Quantum complexity theory allows a physically more reasonable definition of the ‘complexity’ or ‘knowledge’ in a physical system than does classical complexity theory.},
	language = {en},
	number = {1818},
	urldate = {2018-04-16},
	journal = {Proc. R. Soc. Lond. A},
	author = {Deutsch, D.},
	month = jul,
	year = {1985},
	pages = {97--117}
}

@article{bruck_power_1990,
	title = {On the power of neural networks for solving hard problems},
	volume = {6},
	issn = {0885064X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0885064X9090001T},
	doi = {10.1016/0885-064X(90)90001-T},
	abstract = {This paper deals with a neural network model in which each neuron performs a threshold logic function. An important property of the model is that it always converges to a stable state when operating in a serial mode [2,5]. This property is the basis of the potential applications of the model such as associative memory devices and combinatorial optimization [3,6].},
	language = {en},
	number = {2},
	urldate = {2018-04-16},
	journal = {Journal of Complexity},
	author = {Bruck, Jehoshua and Goodman, Joseph W},
	month = jun,
	year = {1990},
	pages = {129--135}
}

@article{rooij_bridging_nodate,
	title = {Bridging the {Gap} between {Theory} and {Practice} of {Approximate} {Bayesian} {Inference}},
	url = {https://www.academia.edu/7092708/Bridging_the_Gap_between_Theory_and_Practice_of_Approximate_Bayesian_Inference},
	abstract = {Bridging the Gap between Theory and Practice of Approximate Bayesian Inference},
	language = {en},
	urldate = {2018-04-15},
	author = {Rooij, Iris van and Kwisthout, Johan}
}

@book{thagard_coherence_2002,
	address = {Cambridge, Mass.},
	edition = {Reprint edition},
	title = {Coherence in {Thought} and {Action}},
	isbn = {978-0-262-70092-4},
	abstract = {This book is an essay on how people make sense of each other and the world they live in. Making sense is the activity of fitting something puzzling into a coherent pattern of mental representations that include concepts, beliefs, goals, and actions. Paul Thagard proposes a general theory of coherence as the satisfaction of multiple interacting constraints, and discusses the theory's numerous psychological and philosophical applications. Much of human cognition can be understood in terms of coherence as constraint satisfaction, and many of the central problems of philosophy can be given coherence-based solutions. Thagard shows how coherence can help to unify psychology and philosophy, particularly when addressing questions of epistemology, metaphysics, ethics, politics, and aesthetics. He also shows how coherence can integrate cognition and emotion.},
	language = {English},
	publisher = {A Bradford Book},
	author = {Thagard, Paul},
	month = aug,
	year = {2002}
}

@article{thagard_coherence_nodate,
	title = {Coherence as {Constraint} {Satisfaction}},
	author = {THAGARD, PAUL and VERBEURGT, KARSTEN},
	pages = {24}
}

@article{reiter_logic_nodate,
	title = {A {Logic} for {Default} {Reasoning}},
	abstract = {The need to make default assumptions is frequently encountered in reasoning'about incompletely specified worlds. Inferences sanctioned by default are best viewed as beliefs which may well be modifiedor rejectedby subsequent observations. It is thisproperty which leads to the non.monotonJcity of any logic of defaults.},
	author = {Reiter, R},
	pages = {52}
}
@article{frank_connectionist_2009,
	title = {Connectionist {Semantic} {Systematicity}},
	volume = {110},
	issn = {0010-0277},
	doi = {10.1016/j.cognition.2008.11.013},
	abstract = {Fodor and Pylyshyn [Fodor, J. A., \& Pylyshyn, Z. W. (1988). Connectionism and cognitive architecture: A critical analysis. "Cognition," 28, 3-71] argue that connectionist models are not able to display systematicity other than by implementing a classical symbol system. This claim entails that connectionism cannot compete with the classical approach as an alternative architectural framework for human cognition. We present a connectionist model of sentence comprehension that does not implement a symbol system yet behaves systematically. It consists in a recurrent neural network that maps sentences describing situations in a microworld, onto representations of these situations. After being trained on particular sentence-situation pairs, the model can comprehend new sentences, even if these describe new situations. We argue that this systematicity arises robustly and in a psychologically plausible manner because it depends on structure inherent in the world. (Contains 15 tables and 6 figures.)},
	language = {en},
	number = {3},
	urldate = {2018-04-15},
	journal = {Cognition},
	author = {Frank, Stefan L. and Haselager, Willem F. G. and van Rooij, Iris},
	month = mar,
	year = {2009},
	keywords = {Cognitive Science, Comprehension, Knowledge Representation, Language Processing, Models, Semantics, Sentences},
	pages = {358--379}
}

@article{fortnow_status_2009,
	title = {The status of the {P} versus {NP} problem},
	volume = {52},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=1562164.1562186},
	doi = {10.1145/1562164.1562186},
	language = {en},
	number = {9},
	urldate = {2018-04-15},
	journal = {Communications of the ACM},
	author = {Fortnow, Lance},
	month = sep,
	year = {2009},
	pages = {78}
}

@article{fortnow_status_2009-1,
	title = {The status of the {P} versus {NP} problem},
	volume = {52},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=1562164.1562186},
	doi = {10.1145/1562164.1562186},
	language = {en},
	number = {9},
	urldate = {2018-04-15},
	journal = {Communications of the ACM},
	author = {Fortnow, Lance},
	month = sep,
	year = {2009},
	pages = {78}
}

@article{dry_human_2006,
	title = {Human {Performance} on {Visually} {Presented} {Traveling} {Salesperson} {Problems} with {Varying} {Numbers} of {Nodes}},
	volume = {1},
	issn = {1932-6246},
	url = {https://docs.lib.purdue.edu/jps/vol1/iss1/4},
	doi = {10.7771/1932-6246.1004},
	abstract = {We investigated the properties of the distribution of human solution times for Traveling Salesperson Problems (TSPs) with increasing numbers of nodes. New experimental data are presented that measure solution times for carefully chosen representative problems with 10, 20, . . . 120 nodes. We compared the solution times predicted by the convex hull procedure proposed by MacGregor and Ormerod (1996), the hierarchical approach of Graham, Joshi, and Pizlo (2000), and by five algorithms drawn from the artificial intelligence and operations research literature. The most likely polynomial model for describing the relationship between mean solution time and the size of a TSP is linear or near-linear over the range of problem sizes tested, supporting the earlier finding of Graham et al. (2000). We argue the properties of the solution time distributions place strong constraints on the development of detailed models of human performance for TSPs, and provide some evaluation of previously proposed models in light of our findings.},
	language = {en},
	number = {1},
	urldate = {2018-04-15},
	journal = {The Journal of Problem Solving},
	author = {Dry, Matthew and Lee, Michael D. and Vickers, Douglas and Hughes, Peter},
	month = dec,
	year = {2006}
}

@book{cherniak_minimal_1986,
	title = {Minimal {Rationality}},
	publisher = {MIT Press},
	author = {Cherniak, Christopher},
	year = {1986}
}

@misc{press_minimal_nodate,
	title = {Minimal {Rationality}},
	url = {https://mitpress.mit.edu/books/minimal-rationality},
	abstract = {In Minimal Rationality, Christopher Cherniak boldly challenges the myth of Man the the Rational Animal and the central role that the "perfectly rational agent" has had in philosophy, psychology, and other cognitive sciences, as well as in economics. His book presents a more realistic theory based on the limits to rationality which can play a similar generative role in the human sciences, and it seeks to determine the minimal rationality an actual agent must possess.},
	language = {en},
	urldate = {2018-04-15},
	journal = {The MIT Press},
	author = {Press, The MIT}
}

@article{chater_probabilistic_2006,
	title = {Probabilistic models of cognition: {Conceptual} foundations},
	volume = {10},
	issn = {13646613},
	shorttitle = {Probabilistic models of cognition},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S136466130600132X},
	doi = {10.1016/j.tics.2006.05.007},
	language = {en},
	number = {7},
	urldate = {2018-04-15},
	journal = {Trends in Cognitive Sciences},
	author = {Chater, Nick and Tenenbaum, Joshua B. and Yuille, Alan},
	month = jul,
	year = {2006},
	pages = {287--291}
}

@book{results_computational_2009,
	address = {Cambridge ; New York},
	edition = {1 edition},
	title = {Computational {Complexity}: {A} {Modern} {Approach}},
	isbn = {978-0-521-42426-4},
	shorttitle = {Computational {Complexity}},
	abstract = {This beginning graduate textbook describes both recent achievements and classical results of computational complexity theory. Requiring essentially no background apart from mathematical maturity, the book can be used as a reference for self-study for anyone interested in complexity, including physicists, mathematicians, and other scientists, as well as a textbook for a variety of courses and seminars. More than 300 exercises are included with a selected hint set. The book starts with a broad introduction to the field and progresses to advanced results. Contents include: definition of Turing machines and basic time and space complexity classes, probabilistic algorithms, interactive proofs, cryptography, quantum computation, lower bounds for concrete computational models (decision trees, communication complexity, constant depth, algebraic and monotone circuits, proof complexity), average-case complexity and hardness amplification, derandomization and pseudorandom constructions, and the PCP theorem.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {results, search and Barak, Boaz},
	month = apr,
	year = {2009}
}

@article{tsotsos_complexity_1990,
	title = {A {Complexity} {Level} {Analysis} of {Vision}},
	volume = {13},
	number = {3},
	journal = {Behavioral and Brain Sciences},
	author = {Tsotsos, John K.},
	year = {1990}
}

@article{frank_connectionist_2009-1,
	title = {Connectionist semantic systematicity},
	volume = {110},
	issn = {00100277},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0010027708002837},
	doi = {10.1016/j.cognition.2008.11.013},
	language = {en},
	number = {3},
	urldate = {2018-04-15},
	journal = {Cognition},
	author = {Frank, Stefan L. and Haselager, Willem F.G. and van Rooij, Iris},
	month = mar,
	year = {2009},
	pages = {358--379}
}

@article{chalmers_computational_2011,
	title = {A {Computational} {Foundation} for the {Study} of {Cognition}},
	volume = {12},
	number = {4},
	journal = {Journal of Cognitive Science},
	author = {Chalmers, David J.},
	year = {2011},
	pages = {323--357}
}

@article{martignon_simplicity_1999,
	title = {Simplicity and {Robustness} of {Fast} and {Frugal} {Heuristics}},
	volume = {9},
	issn = {0924-6495},
	url = {https://doi.org/10.1023/A:1008313020307},
	doi = {10.1023/A:1008313020307},
	abstract = {Intractability and optimality are two sides of one coin: Optimal models are often intractable, that is, they tend to be excessively complex, or NP-hard. We explain the meaning of NP-hardness in detail and discuss how modem computer science circumvents intractability by introducing heuristics and shortcuts to optimality, often replacing optimality by means of sufficient sub-optimality. Since the principles of decision theory dictate balancing the cost of computation against gain in accuracy, statistical inference is currently being reshaped by a vigorous new trend: the science of simplicity. Simple models, as we show for specific cases, are not just tractable, they also tend to be robust. Robustness is the ability of a model to extract relevant information from data, disregarding noise.Recently, Gigerenzer, Todd and the ABC Research Group (1999) have put forward a collection of fast and frugal heuristics as simple, boundedly rational inference strategies used by the unaided mind in real world inference problems. This collection of heuristics has suggestively been called the adaptive toolbox. In this paper we will focus on a comparison task in order to illustrate the simplicity and robustness of some of the heuristics in the adaptive toolbox in contrast to the intractability and the fragility of optimal solutions. We will concentrate on three important classes of models for comparison-based inference and, in each of these classes, search for that to be used as benchmarks to evaluate the performance of fast and frugal heuristics: lexicographic trees, linear modes and Bayesian networks. Lexicographic trees are interesting because they are particularly simple models that have been used by humans throughout the centuries. Linear models have been traditionally used by cognitive psychologists as models for human inference, while Bayesian networks have only recently been introduced in statistics and computer science. Yet it is the Bayesian networks that are the best possible benchmarks for evaluating the fast and frugal heuristics, as we will show in this paper.},
	number = {4},
	urldate = {2018-04-12},
	journal = {Minds Mach.},
	author = {Martignon, Laura and Schmitt, Michael},
	month = nov,
	year = {1999},
	keywords = {Bayesian networks, NP-hardness, algorithms, generalization, heuristics, linear models},
	pages = {565--593}
}

@misc{noauthor_invariants_nodate,
	title = {Invariants of {Human} {Behavior} {\textbar} {Annual} {Review} of {Psychology}},
	url = {https://www.annualreviews.org/doi/abs/10.1146/annurev.ps.41.020190.000245},
	urldate = {2018-04-11}
}

@article{parberry_knowledge_1997,
	title = {Knowledge, {Understanding}, and {Computational} {Complexity}},
	abstract = {Searle’s arguments that intelligence cannot arise from formal programs are refuted by arguing that his analogies and thought-experiments are fundamentally ﬂawed: he imagines a world in which computation is free. It is argued instead that although cognition may in principle be realized by symbol processing machines, such a computation is likely to have resource requirements that would prevent a symbol processing program for cognition from being designed, implemented, or executed. In the course of the argument the following observations are made: (1) A system can have knowledge, but no understanding. (2) Understanding is a method by which cognitive computations are carried out with limited resources. (3) Introspection is inadequate for analyzing the mind. (4) Simulation of the brain by a computer is unlikely not because of the massive computational power of the brain, but because of the overhead required when one model of computation is simulated by another. (5) Intentionality is a property that arises from systems of suﬃcient computational power that have the appropriate design. (6) Models of cognition can be developed in direct analogy with technical results from the ﬁeld of computational complexity theory.},
	author = {Parberry, Ian},
	year = {1997},
	pages = {19}
}

@misc{noauthor_4_nodate,
	title = {(4) {Coherence}: {The} {Price} of the {Ticket}},
	shorttitle = {(4) {Coherence}},
	url = {https://www.researchgate.net/publication/261743208_Coherence_The_Price_of_the_Ticket},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2018-04-11},
	journal = {ResearchGate}
}

@misc{noauthor_psycnet_nodate,
	title = {{PsycNET}},
	url = {http://psycnet.apa.org/doiLanding?doi=10.1037%2F0033-295X.115.1.230},
	urldate = {2018-04-11}
}

@misc{noauthor_psycnet_nodate-1,
	title = {{PsycNET} {Record} {Display} - {PsycNET}},
	url = {http://psycnet.apa.org/record/2008-00265-013},
	urldate = {2018-04-11}
}

@article{gigerenzer_fast_2008,
	title = {Fast and {Frugal} {Heuristics} {Are} {Plausible} {Models} of {Cognition}: {Reply} to {Dougherty}, {Franco}-{Watkins}, and {Thomas} (2008)},
	volume = {115},
	issn = {0033-295X},
	shorttitle = {Fast and {Frugal} {Heuristics} {Are} {Plausible} {Models} of {Cognition}},
	abstract = {M. R. Dougherty, A. M. Franco-Watkins, and R. Thomas (2008) conjectured that fast and frugal heuristics need an automatic frequency counter for ordering cues. In fact, only a few heuristics order cues, and these orderings can arise from evolutionary, social, or individual learning, none of which requires automatic frequency counting. The idea that cue validities cannot be computed because memory does not encode missing information is misinformed; it implies that measures of co-occurrence are incomputable and would invalidate most theories of cue learning. They also questioned the recognition heuristic's psychological plausibility on the basis of their belief that it has not been implemented in a memory model, although it actually has been implemented in ACT-R (L. J. Schooler \& R. Hertwig, 2005). On the positive side, M. R. Dougherty et al. discovered a new mechanism for a less-is-more effect. The authors of the present article specify minimal criteria for psychological plausibility, describe some genuine challenges in the study of heuristics, and conclude that fast and frugal heuristics are psychologically plausible: They use limited search and are tractable and robust.},
	language = {en},
	number = {1},
	urldate = {2018-04-11},
	journal = {Psychological Review},
	author = {Gigerenzer, Gerd and Hoffrage, Ulrich and Goldstein, Daniel G.},
	month = jan,
	year = {2008},
	keywords = {Cognitive Processes, Cues, Heuristics, Learning Theories, Memory, Models, Psychology},
	pages = {230--237}
}

@article{marr_artificial_1977,
	title = {Artificial {Intelligence}: {A} {Personal} {View}},
	volume = {9},
	shorttitle = {Artificial {Intelligence}},
	number = {September},
	journal = {Artificial Intelligence},
	author = {Marr, David},
	year = {1977},
	pages = {37--48}
}

@misc{noauthor_tractable_nodate,
	title = {The {Tractable} {Cognition} {Thesis} - {Van} {Rooij} - 2008 - {Cognitive} {Science} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/epdf/10.1080/03640210801897856},
	urldate = {2018-04-08}
}

@article{meehl_appraising_1990,
	title = {Appraising and amending theories: {The} strategy of {Lakatosian} defense and two principles that warrant it},
	volume = {1},
	shorttitle = {Appraising and amending theories},
	number = {2},
	journal = {Psychological Inquiry},
	author = {Meehl, Paul E.},
	year = {1990},
	pages = {108--141}
}

@article{meehl_why_1990,
	title = {Why {Summaries} of {Research} on {Psychological} {Theories} are {Often} {Uninterpretable}},
	volume = {66},
	issn = {0033-2941},
	url = {https://doi.org/10.2466/pr0.1990.66.1.195},
	doi = {10.2466/pr0.1990.66.1.195},
	abstract = {Null hypothesis testing of correlational predictions from weak substantive theories in soft psychology is subject to the influence of ten obfuscating factors whose effects are usually (1) sizeable, (2) opposed, (3) variable, and (4) unknown. The net epistemic effect of these ten obfuscating influences is that the usual research literature review is well-nigh uninterpretable. Major changes in graduate education, conduct of research, and editorial policy are proposed.},
	language = {en},
	number = {1},
	urldate = {2018-03-06},
	journal = {Psychological Reports},
	author = {Meehl, Paul E.},
	month = feb,
	year = {1990},
	pages = {195--244}
}

@misc{noauthor_search_nodate,
	title = {Search {Results} [ru.on.worldcat.org]},
	url = {https://ru.on.worldcat.org/search?databaseList=2474%2C3441%2C2273%2C2194%2C1931%2C1697%2C2268%2C3313%2C2267%2C3036%2C638%2C2507%2C1978%2C3012%2C3374%2C3450%2C3250%2C2437%2C3448%2C1941%2C2237%2C2236%2C3049%2C1982%2C2795%2C2233%2C2375%2C1164%2C2175%2C3384%2C2294%2C3382%2C3218%2C1953%2C1875%2C3018%2C3336%2C2005%2C1674%2C3378%2C2443%2C1672%2C1834%2C2221%2C3155%2C2264%2C3551%2C2462%2C2262%2C3197%2C2261%2C2260%2C3195%2C2977%2C3548%2C1524%2C1842%2C2259%2C2897%2C3225%2C1847%2C3988%2C3429&queryString=Strategy+Selection+as+Rational+Metareasoning&clusterResults=false#/oclc/7083980581},
	urldate = {2018-03-06}
}

@article{lieder_f._strategy_2017,
	title = {Strategy selection as rational metareasoning},
	volume = {124},
	issn = {0033-295X},
	number = {6},
	journal = {Psychological Review},
	author = {{Lieder F.} and {Griffiths T.L.}},
	year = {2017},
	pages = {762--794}
}

@misc{noauthor_psycnet_nodate-2,
	title = {{PsycNET} {Record} {Display} - {PsycNET}},
	url = {http://psycnet.apa.org/record/2017-49501-002},
	urldate = {2018-03-06}
}

@phdthesis{van_rooij_tractable_nodate,
	title = {Tractable {Cognition}: {Complexity} {Theory} in {Cognitive} {Psychology}},
	author = {Van Rooij, Iris}
}

@article{schmitt_complexity_2006,
	title = {On the {Complexity} of {Learning} {Lexicographic} {Strategies}},
	volume = {7},
	issn = {1532-4435},
	url = {http://dl.acm.org/citation.cfm?id=1248547.1248550},
	abstract = {Fast and frugal heuristics are well studied models of bounded rationality. Psychological research has proposed the take-the-best heuristic as a successful strategy in decision making with limited resources. Take-the-best searches for a sufficiently good ordering of cues (or features) in a task where objects are to be compared lexicographically. We investigate the computational complexity of finding optimal cue permutations for lexicographic strategies and prove that the problem is NP-complete. It follows that no efficient (that is, polynomial-time) algorithm computes optimal solutions, unless P=NP. We further analyze the complexity of approximating optimal cue permutations for lexicographic strategies. We show that there is no efficient algorithm that approximates the optimum to within any constant factor, unless P=NP. The results have implications for the complexity of learning lexicographic strategies from examples. They show that learning them in polynomial time within the model of agnostic probably approximately correct (PAC) learning is impossible, unless RP=NP. We further consider greedy approaches for building lexicographic strategies and determine upper and lower bounds for the performance ratio of simple algorithms. Moreover, we present a greedy algorithm that performs provably better than take-the-best. Tight bounds on the sample complexity for learning lexicographic strategies are also given in this article.},
	urldate = {2018-03-06},
	journal = {J. Mach. Learn. Res.},
	author = {Schmitt, Michael and Martignon, Laura},
	month = dec,
	year = {2006},
	pages = {55--83}
}

@phdthesis{sweers_adapting_2015,
	title = {Adapting the {Adaptive} {Toolbox}: {The} computational cost of building rational behavior},
	shorttitle = {Adapting the {Adaptive} {Toolbox}},
	author = {Sweers, M. S.},
	year = {2015}
}

@incollection{haselager_lazy_2008,
	title = {A lazy brain? {Embodied} embedded cognition and cognitive neuroscience},
	volume = {5},
	shorttitle = {A lazy brain?},
	booktitle = {Handbook of cognitive science: {An} embodied approach},
	author = {Haselager, Pim and van Dijk, Jelle and van Rooij, Iris},
	year = {2008},
	pages = {273--287}
}

@article{todd_ecological_2000,
	title = {Ecological rationality and its contents},
	volume = {6},
	number = {4},
	journal = {Thinking \& Reasoning},
	author = {Todd, M. and Fiddick, Laurence and Krauss, Stefan},
	year = {2000},
	pages = {375--384}
}

@article{stevens_evolutionary_2008,
	title = {The evolutionary biology of decision making},
	author = {Stevens, Jeffrey R.},
	year = {2008}
}

@inproceedings{lieder_when_2015,
	title = {When to use which heuristic: {A} rational solution to the strategy selection problem.},
	shorttitle = {When to use which heuristic},
	booktitle = {{CogSci}},
	author = {Lieder, Falk and Griffiths, Thomas L.},
	year = {2015}
}

@article{martignon_simplicity_1999-1,
	title = {Simplicity and robustness of fast and frugal heuristics},
	volume = {9},
	number = {4},
	journal = {Minds and machines},
	author = {Martignon, Laura and Schmitt, Michael},
	year = {1999},
	pages = {565--593}
}

@article{shaw_agent-environment_2003,
	title = {The agent-environment interface: {Simon}'s indirect or {Gibson}'s direct coupling?},
	volume = {15},
	shorttitle = {The agent-environment interface},
	number = {1},
	journal = {Ecological Psychology},
	author = {Shaw, Robert},
	year = {2003},
	pages = {37--106}
}

@misc{noauthor_rh_fast_2009_nodate,
	title = {{RH}\_Fast\_2009 ({faST} {aNd} {fRuGal} {hEuRiSTiCS}- {TOOlS} {Of} {SOCial} {RaTiONaliTy}).pdf}
}

@misc{noauthor_rational_nodate,
	title = {Rational strategy selection\_FalkLieder.pdf}
}

@inproceedings{garcia-retamero_how_2006,
	title = {How to learn good cue orders: {When} social learning benefits simple heuristics},
	shorttitle = {How to learn good cue orders},
	booktitle = {Proceedings of the 28th annual conference of the {Cognitive} {Science} {Society}},
	publisher = {Erlbaum Hillsdale, NJ},
	author = {Garcia-Retamero, Rocio and Takezawa, Masanori and Gigerenzer, Gerd},
	year = {2006},
	pages = {1352--1358}
}

@article{vul_one_2014,
	title = {One and {Done}? {Optimal} {Decisions} {From} {Very} {Few} {Samples}},
	volume = {38},
	issn = {03640213},
	shorttitle = {One and {Done}?},
	url = {http://doi.wiley.com/10.1111/cogs.12101},
	doi = {10.1111/cogs.12101},
	language = {en},
	number = {4},
	urldate = {2018-03-06},
	journal = {Cognitive Science},
	author = {Vul, Edward and Goodman, Noah and Griffiths, Thomas L. and Tenenbaum, Joshua B.},
	month = may,
	year = {2014},
	pages = {599--637}
}

@article{martignon_naive_2003,
	title = {Naive and yet enlightened: {From} natural frequencies to fast and frugal decision trees},
	shorttitle = {Naive and yet enlightened},
	journal = {Thinking: Psychological perspectives on reasoning, judgment and decision making},
	author = {Martignon, Laura and Vitouch, Oliver and Takezawa, Masanori and Forster, Malcolm R.},
	year = {2003},
	pages = {189--211}
}

@inproceedings{milli_when_2017,
	title = {When does bounded-optimal metareasoning favor few cognitive systems?},
	booktitle = {{AAAI}},
	author = {Milli, Smitha and Lieder, Falk and Griffiths, Thomas L.},
	year = {2017},
	pages = {4422--4428}
}

@inproceedings{lee_representation_2007,
	title = {The representation of judgment heuristics and the generality problem},
	volume = {29},
	booktitle = {Proceedings of the {Annual} {Meeting} of the {Cognitive} {Science} {Society}},
	author = {Lee, Carole J.},
	year = {2007}
}

@article{arkes_how_2016,
	title = {How bad is incoherence?},
	volume = {3},
	issn = {2325-9973, 2325-9965},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/dec0000043},
	doi = {10.1037/dec0000043},
	language = {en},
	number = {1},
	urldate = {2018-03-06},
	journal = {Decision},
	author = {Arkes, Hal R. and Gigerenzer, Gerd and Hertwig, Ralph},
	year = {2016},
	pages = {20--39}
}

@article{gigerenzer_heuristic_2011,
	title = {Heuristic {Decision} {Making}},
	volume = {62},
	issn = {0066-4308, 1545-2085},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-psych-120709-145346},
	doi = {10.1146/annurev-psych-120709-145346},
	language = {en},
	number = {1},
	urldate = {2018-03-06},
	journal = {Annual Review of Psychology},
	author = {Gigerenzer, Gerd and Gaissmaier, Wolfgang},
	month = jan,
	year = {2011},
	pages = {451--482}
}

@book{gigerenzer_bounded_2001,
	address = {Cambridge, Mass},
	title = {Bounded rationality: the adaptive toolbox},
	isbn = {978-0-262-07214-4},
	shorttitle = {Bounded rationality},
	publisher = {MIT Press},
	editor = {Gigerenzer, Gerd and Selten, Reinhard},
	year = {2001},
	keywords = {Decision making, Reasoning}
}

@article{cronbach_construct_1955,
	title = {Construct validity in psychological tests.},
	volume = {52},
	number = {4},
	journal = {Psychological bulletin},
	author = {Cronbach, Lee J. and Meehl, Paul E.},
	year = {1955},
	pages = {281}
}

@article{van_rooij_intractability_2012,
	title = {Intractability and approximation of optimization theories of cognition},
	volume = {56},
	number = {4},
	journal = {Journal of Mathematical Psychology},
	author = {van Rooij, Iris and Wareham, Todd},
	year = {2012},
	pages = {232--247}
}

@article{kwisthout_bridging_2013,
	title = {Bridging the gap between theory and practice of approximate {Bayesian} inference},
	volume = {24},
	journal = {Cognitive Systems Research},
	author = {Kwisthout, Johan and Van Rooij, Iris},
	year = {2013},
	pages = {2--8}
}

@article{blokpoel_when_2012,
	title = {When can predictive brains be truly {Bayesian}?},
	volume = {3},
	journal = {Frontiers in psychology},
	author = {Blokpoel, Mark and Kwisthout, Johan and van Rooij, Iris},
	year = {2012},
	pages = {406}
}

@inproceedings{mueller_similarity_2009,
	title = {Similarity as tractable transformation},
	volume = {31},
	author = {Mueller, Mortiz and Wareham, Todd and Van Rooij, Iris},
	year = {2009}
}

@article{van_rooij_intentional_2011,
	title = {Intentional communication: {Computationally} easy or difficult?},
	volume = {5},
	shorttitle = {Intentional communication},
	journal = {Frontiers in Human Neuroscience},
	author = {Van Rooij, Iris and Kwisthout, Johan and Blokpoel, Mark and Szymanik, Jakub and Wareham, Todd and Toni, Ivan},
	year = {2011},
	pages = {52}
}

@article{van_rooij_rational_2018,
	title = {Rational analysis, intractability, and the prospects of ‘as if’-explanations},
	volume = {195},
	number = {2},
	journal = {Synthese},
	author = {van Rooij, Iris and Wright, Cory D. and Kwisthout, Johan and Wareham, Todd},
	year = {2018},
	pages = {491--510}
}

@article{van_rooij_intractability_2012-1,
	title = {Intractability and the use of heuristics in psychological explanations},
	volume = {187},
	number = {2},
	journal = {Synthese},
	author = {Van Rooij, Iris and Wright, Cory D. and Wareham, Todd},
	year = {2012},
	pages = {471--487}
}

@inproceedings{blokpoel_how_2010,
	title = {How action understanding can be rational, {Bayesian} and tractable},
	volume = {32},
	author = {Blokpoel, Mark and Kwisthout, Johan and Van der Weide, Theo P. and Van Rooij, Iris},
	year = {2010}
}

@article{kwisthout_bayesian_2011,
	title = {Bayesian intractability is not an ailment that approximation can cure},
	volume = {35},
	number = {5},
	journal = {Cognitive Science},
	author = {Kwisthout, Johan and Wareham, Todd and van Rooij, Iris},
	year = {2011},
	pages = {779--784}
}

@article{van_rooij_perceptual_2006,
	title = {Perceptual or {Analytical} processing? {Evidence} from children's and adult's performance on the {Euclidean} traveling salesperson problem},
	volume = {1},
	shorttitle = {Perceptual or {Analytical} processing?},
	number = {1},
	journal = {The Journal of Problem Solving},
	author = {van Rooij, Iris and Schactman, Alissa and Kadlec, Helena and Stege, Ulrike},
	year = {2006},
	pages = {6}
}
@article{van_rooij_convex_2003,
	title = {Convex hull and tour crossings in the {Euclidean} traveling salesperson problem: {Implications} for human performance studies},
	volume = {31},
	shorttitle = {Convex hull and tour crossings in the {Euclidean} traveling salesperson problem},
	number = {2},
	journal = {Memory \& cognition},
	author = {Van Rooij, Iris and Stege, Ulrike and Schactman, Alissa},
	year = {2003},
	pages = {215--220}
}

@article{tak_tours_2008,
	title = {Some tours are more equal than others: {The} convex-hull model revisited with lessons for testing models of the traveling salesperson problem},
	shorttitle = {Some tours are more equal than others},
	author = {Tak, Susanne and Plaisier, Marco and van Rooij, IJEI},
	year = {2008}
}

@article{van_rooij_tractable_2008,
	title = {The {Tractable} {Cognition} {Thesis}},
	volume = {32},
	issn = {0364-0213},
	url = {http://doi.wiley.com/10.1080/03640210801897856},
	doi = {10.1080/03640210801897856},
	language = {en},
	number = {6},
	urldate = {2017-11-30},
	journal = {Cognitive Science: A Multidisciplinary Journal},
	author = {van Rooij, Iris},
	month = sep,
	year = {2008},
	pages = {939--984}
}